{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from eden.util import configure_logging\n",
    "import logging\n",
    "configure_logging(logging.getLogger(),verbosity=2)\n",
    "%matplotlib inline\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get data\n",
    "from eden.converter.graph.gspan import gspan_to_eden\n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "def clean(graphs):\n",
    "    for g in graphs:\n",
    "        for n,d in g.nodes(data=True):\n",
    "            d.pop('weight')\n",
    "        yield g\n",
    "\n",
    "def get_graphs(dataset_fname='bursi.pos.gspan', size=100):\n",
    "    return  clean(islice(gspan_to_eden(dataset_fname),size))\n",
    "\n",
    "\n",
    "#dataset_names = !cat NCI60/names\n",
    "#dataset = dataset_names[4]\n",
    "#dataset_fname = 'NCI60/' + dataset + '_orig_pos.gspan'\n",
    "#print 'Working with dataset: %s' % dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''DEBUGGING VECTORIZA'''\n",
    "from graphlearn.utils import draw\n",
    "import graphlearn.abstract_graphs.molecules as mole\n",
    "from graphlearn.graphlearn import GraphLearnSampler as GLS\n",
    "from eden.graph import Vectorizer\n",
    "\n",
    "vectorizer=Vectorizer()\n",
    "graphs=get_graphs()\n",
    "g=graphs.next()\n",
    "g=vectorizer._graph_preprocessing(g)\n",
    "\n",
    "\n",
    "gm=mole.MolecularGraphWrapper(g,vectorizer,base_thickness_list=[2])\n",
    "gn=gm.graph(nested=True)\n",
    "\n",
    "#gn=vectorizer._graph_preprocessing(gn)\n",
    "gn=vectorizer._edge_to_vertex_transform(gn)\n",
    "draw.graphlearn(gn,size=20)\n",
    "v=vectorizer.transform_single(gn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''TESTING EXTRACTION AND GRAPHMANAGER'''\n",
    "from graphlearn.utils import draw\n",
    "import graphlearn.abstract_graphs.molecules as mole\n",
    "from graphlearn.graphlearn import GraphLearnSampler as GLS\n",
    "from eden.graph import Vectorizer\n",
    "\n",
    "vectorizer=Vectorizer()\n",
    "\n",
    "print 'DEMONSTRATING GRAPH MANAGER'\n",
    "graphs=get_graphs()\n",
    "\n",
    "for i in range(2):\n",
    "    print 'grammar example %d' % i\n",
    "    g=graphs.next()\n",
    "    gm=mole.MolecularGraphWrapper(g,vectorizer,base_thickness_list=[2])\n",
    "    #g=gm.graph(nested=True)\n",
    "    #print g.nodes(data=True)\n",
    "    #g.node[0].pop('weight')\n",
    "    #vec=vectorizer.transform_single(g)\n",
    "    draw.graphlearn([gm.graph(nested=True),gm.abstract_graph(),gm.base_graph()], size = 15,vertex_label = 'label',contract=False)\n",
    "\n",
    "    \n",
    "print 'DEMONSTRATING EXTRACTION'  \n",
    "radius_list=[0,2]\n",
    "thickness_list=[2,4]\n",
    "base_thickness_list=[2]\n",
    "argz=(gm,radius_list,thickness_list,Vectorizer(),2**20-1,lambda x,y:True, base_thickness_list)\n",
    "\n",
    "cips=gm.all_core_interface_pairs(thickness_list=[2],radius_list=[0,1],hash_bitmask=2**20-1)\n",
    "draw.graphlearn(cips[0][0].graph, contract=False)\n",
    "\n",
    "\n",
    "g=gm.graph(nested=False)\n",
    "print 'test', g.nodes(data=True)[0][1]\n",
    "#g.node[0].pop('weight')\n",
    "vec=vectorizer.transform_single(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "'''\n",
    "learning a grammar\n",
    "'''\n",
    "import graphlearn.abstract_graphs.molecules as mole\n",
    "from graphlearn.graphlearn import GraphLearnSampler as GLS\n",
    "graphs = get_graphs(size=600)\n",
    "sampler=GLS(radius_list=[0,1],thickness_list=[1], min_cip_count=2, min_interface_count=2, preprocessor=mole.PreProcessor(base_thickness_list=[2]))\n",
    "sampler.fit(graphs,n_jobs=1,batch_size=1)\n",
    "sampler.save('tmp/mole_ubergrammar.ge')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#draw production rules\n",
    "draw.draw_grammar(sampler.lsgg.productions,n_productions=5,n_graphs_per_production=5,\n",
    "                     n_graphs_per_line=5, size=9, contract=False,\n",
    "                     colormap='Paired', invert_colormap=False,node_border=1,\n",
    "                     vertex_alpha=0.6, edge_alpha=0.5, node_size=450, abstract_interface=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "'''\n",
    "Molecule sampling\n",
    "'''\n",
    "import os\n",
    "os.nice(19)\n",
    "import graphlearn.utils.draw as draw\n",
    "import graphlearn.abstract_graphs.molecules as mole\n",
    "import itertools\n",
    "#sampler=mole.MolecularSampler()\n",
    "#sampler.load('tmp/mole_ubergrammar.ge')\n",
    "graphs = get_graphs()\n",
    "\n",
    "id_start=15\n",
    "id_end=id_start+9\n",
    "graphs = itertools.islice(graphs,id_start,id_end)\n",
    "n_steps=100\n",
    "\n",
    "graphs = sampler.sample(graphs,\n",
    "                        n_samples=5,\n",
    "                        batch_size=1,\n",
    "                        n_steps=n_steps,\n",
    "                        n_jobs=1,\n",
    "                        quick_skip_orig_cip=True,\n",
    "                        probabilistic_core_choice=False,\n",
    "                        burnin=0,\n",
    "                        improving_threshold=0.5,\n",
    "                        max_core_size_diff=-1,\n",
    "                        select_cip_max_tries=100,\n",
    "                        keep_duplicates=True,\n",
    "                        omit_seed=False)\n",
    "\n",
    " \n",
    "scores=[]\n",
    "ids=range(id_start,id_end)\n",
    "for i,graph in enumerate(graphs):\n",
    "    print 'Graph id: %d'%(ids[i])\n",
    "    scores.append(graph.graph['sampling_info']['score_history'])\n",
    "    path_graphs = graph.graph['sampling_info']['graphs_history']\n",
    "    \n",
    "\n",
    "    path_graphs= list(path_graphs)\n",
    "    draw.graphlearn(path_graphs,\n",
    "                           n_graphs_per_line=5, size=10, \n",
    "                           colormap='Paired', invert_colormap=False,node_border=0.5, vertex_color='color_level',\n",
    "                           vertex_alpha=0.5, edge_alpha=0.7, node_size=450,edge_label='label',\n",
    "                          headlinehook= draw.get_score_of_graph\n",
    "                          )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "step=1\n",
    "num_graphs_per_plot=3\n",
    "num_plots=np.ceil([len(scores)/num_graphs_per_plot])\n",
    "for i in range(num_plots):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    for j,score in enumerate(scores[i*num_graphs_per_plot:i*num_graphs_per_plot+num_graphs_per_plot]):\n",
    "        data = list(islice(score,None, None, step))\n",
    "        plt.plot(data, label='graph %d'%(j+i*num_graphs_per_plot+id_start))\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.ylim(-0.1,1.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import graphlearn.abstract_graphs.molecules as mole\n",
    "from graphlearn.utils import draw\n",
    "from eden.graph import Vectorizer\n",
    "v=Vectorizer()\n",
    "from graphlearn.abstract_graphs.molecules import node_to_cycle\n",
    "import networkx as nx\n",
    "import eden\n",
    "\n",
    "def make_abstract(graph):\n",
    "    '''\n",
    "    make sure this is not expanded\n",
    "    '''\n",
    "    # prepare fast hash function\n",
    "    def fhash(stuff):\n",
    "        return eden.fast_hash(stuff, 2 ** 20 - 1)\n",
    "    \n",
    "    \n",
    "    # all nodes get their cycle calculated\n",
    "    for n, d in graph.nodes(data=True):\n",
    "        d['cycle'] = list(node_to_cycle(graph, n))\n",
    "        d['cycle'].sort()\n",
    "        #if 'parent'in d:\n",
    "        #    d.pop('parent')\n",
    "            \n",
    "\n",
    "    \n",
    "    # make sure most of the abstract nodes are created.\n",
    "    abstract_graph = nx.Graph()\n",
    "    for n, d in graph.nodes(data=True):\n",
    "        cyclash = fhash(d['cycle'])\n",
    "        if cyclash not in abstract_graph.node:\n",
    "            abstract_graph.add_node(cyclash)\n",
    "            abstract_graph.node[cyclash]['contracted'] = set(d['cycle'])\n",
    "            abstract_graph.node[cyclash]['node'] = True\n",
    "            # it is possible that a node belongs to more than 1 cycle, so...\n",
    "            # each node gets parents\n",
    "            for e in d['cycle']:\n",
    "                node = graph.node[e]\n",
    "                if 'parent' not in node:\n",
    "                    node['parent'] = set()\n",
    "                node['parent'].add(cyclash)\n",
    "\n",
    "\n",
    "    \n",
    "    #  HERE THE ACTUAL ABSTRACTION BEGINS\n",
    "\n",
    "    # connect nodes in the abstract graph\n",
    "    get_element = lambda x: list(x)[0]\n",
    "\n",
    "\n",
    "    \n",
    "    # FOR ALL ABSTRACT NODES\n",
    "    for n, d in abstract_graph.nodes(data=True):\n",
    "        # FIND A LABEL\n",
    "        if len(d['contracted']) > 1:\n",
    "            labels = [ord(graph.node[childid]['label']) for childid in d['contracted']]\n",
    "            labels.sort()\n",
    "            d['label'] = \"cycle\" #fhash(labels)\n",
    "\n",
    "        else:\n",
    "            d['label'] = graph.node[get_element(d['contracted'])]['label']\n",
    "\n",
    "      \n",
    " \n",
    "        # THEN LOOK AT ALL CONTRACTED NODES TO FIND OUT WHAT CONNECTION WE HAVE TO OUR NEIGHBORS\n",
    "        for base_node in d['contracted']:\n",
    "            base_neighbors = graph.neighbors(base_node)\n",
    "            # for all the neighbors\n",
    "            for neigh in base_neighbors:\n",
    "                \n",
    "                \n",
    "                # find out if we have to build a connector node\n",
    "                if len(graph.node[neigh]['cycle']) > 1 and len(d['contracted']) > 1:\n",
    "\n",
    "                    for other in graph.node[neigh]['parent']:\n",
    "                        if other != n:\n",
    "                            l = [other, n]\n",
    "                            l.sort()\n",
    "                            connector = fhash(l)\n",
    "                            \n",
    "                            \n",
    "                            shared_nodes = abstract_graph.node[other]['contracted'] & d['contracted']\n",
    "                            if len(shared_nodes)==0:\n",
    "                                label='e'\n",
    "                            else:\n",
    "                                labels = [ord(graph.node[sid]['label']) for sid in shared_nodes]\n",
    "                                labels.sort()\n",
    "                                share_hash = fhash(labels)\n",
    "                                label='share:'+str(share_hash)\n",
    "                            abstract_graph.add_edge(other,n,label=label)\n",
    "                            '''\n",
    "                            if connector not in abstract_graph.node:\n",
    "                                # we need to consider making the edge the actual intersect of the two...\n",
    "\n",
    "                                abstract_graph.add_node(connector)\n",
    "                                abstract_graph.node[connector]['edge'] = True\n",
    "\n",
    "                                # abstract_graph.node[connector]['label']='edge'\n",
    "                                shared_nodes = abstract_graph.node[other]['contracted'] & d['contracted']\n",
    "                                labels = [ord(graph.node[sid]['label']) for sid in shared_nodes]\n",
    "                                labels.sort()\n",
    "                                share_hash = fhash(labels)\n",
    "\n",
    "\n",
    "                                abstract_graph.node[connector]['label'] = \"shared\" + str(share_hash)\n",
    "\n",
    "                                abstract_graph.add_edge(other, connector)\n",
    "                                abstract_graph.add_edge(connector, n)\n",
    "                            '''\n",
    "                else:\n",
    "                    for e in graph.node[neigh]['parent']:\n",
    "                        abstract_graph.add_edge(n, e, label='e')\n",
    "    return abstract_graph\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def graphor(base,abstr,nested=True):\n",
    "    g= nx.disjoint_union(base, abstr)\n",
    "    node_id= len(g)\n",
    "\n",
    "    for n,d in g.nodes(data=True):\n",
    "        if 'contracted' in d and 'edge' not in d:\n",
    "            for e in d['contracted']:\n",
    "                if 'edge' not in g.node[e]:\n",
    "                    # we want an edge from n to e\n",
    "                    g.add_node(node_id,edge=True,label='e')\n",
    "                    g.add_edge( n, node_id, nesting=True)\n",
    "                    g.add_edge( node_id, e, nesting=True)\n",
    "                    #g.add_edge( n, e, nesting=True)\n",
    "                    node_id+=1\n",
    "    return g\n",
    "    \n",
    "\n",
    "\n",
    "gr=get_graphs()\n",
    "for i in range(1):\n",
    "    g=gr.next()\n",
    "    ab=make_abstract(g)\n",
    "    \n",
    "    g=v._edge_to_vertex_transform(g)\n",
    "    ab=v._edge_to_vertex_transform(ab)\n",
    "    zz=graphor(g,ab)\n",
    "    draw.graphlearn([g,ab], size=20)\n",
    "    v.transform_single(zz)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
