{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from eden.util import configure_logging\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import tee, chain, islice\n",
    "import numpy as np\n",
    "import random\n",
    "from time import time\n",
    "import datetime\n",
    "from graphlearn.graphlearn import GraphLearnSampler\n",
    "from eden.util import fit,predict\n",
    "from eden.graph import Vectorizer\n",
    "# get data\n",
    "from eden.converter.graph.gspan import gspan_to_eden\n",
    "from itertools import islice\n",
    "def get_graphs(dataset_fname, size=100):\n",
    "    return  islice(gspan_to_eden(dataset_fname),size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_sample(graphs):\n",
    "    graphs, graphs_ = tee(graphs)\n",
    "    sampler=GraphLearnSampler(radius_list=[0,1],thickness_list=[1],\n",
    "                              min_cip_count=2, min_interface_count=2,\n",
    "                              vectorizer=Vectorizer(5))\n",
    "    \n",
    "    sampler.fit(graphs, nu=0.3, n_jobs=-1)\n",
    "\n",
    "    logger.info('graph grammar stats:')\n",
    "    interface_counts, core_counts, cip_counts = sampler.grammar().size()\n",
    "    logger.info('#interfaces: %d   #cores: %d   #core-interface-pairs: %d' % (interface_counts, core_counts, cip_counts))\n",
    "    graphs = sampler.sample(graphs_,\n",
    "                            n_steps=5, n_samples=4,\n",
    "                            target_orig_cip=True,\n",
    "                            probabilistic_core_choice=False,\n",
    "                            score_core_choice= True,\n",
    "                            max_core_size_diff=0,\n",
    "                            generator_mode=True,\n",
    "                            improving_threshold=0.3, accept_static_penalty=0,\n",
    "                            n_jobs=-1,burnin=1,select_cip_max_tries=200,keep_duplicates=True)\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_and_evaluate(original, sampled, local_estimator):\n",
    "    outputs = []\n",
    "    for desc,train in [('original',original),\n",
    "                           ('sample',sampled)]:\n",
    "        train,train_ = tee(train)\n",
    "        size=sum(1 for x in train_)\n",
    "        logger.info( \"-\"*80)\n",
    "        logger.info( 'working on %s'%(desc))\n",
    "        logger.info( 'training set sizes: #: %d'%(size))\n",
    "        if size == 0:\n",
    "            logger.info( 'WARNING: empty dataset')\n",
    "            outputs.append(0)\n",
    "        else:\n",
    "            start=time()\n",
    "            predictions = predict(train, \n",
    "                              estimator=local_estimator, \n",
    "                              vectorizer=Vectorizer(4), \n",
    "                              mode='predict_proba',\n",
    "                              n_jobs=-1)\n",
    "            avg_score=np.mean(predictions[:,1])\n",
    "            logger.info( 'avg score: %.5f' % avg_score)\n",
    "            outputs.append(avg_score)\n",
    "            logger.info( 'elapsed: %.1f sec'%(time()-start))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(data_fname, size=None, percentages=None, n_repetitions=None, train_test_split=None):\n",
    "    # initializing \n",
    "    graphs = get_graphs(data_fname, size=size)\n",
    "\n",
    "    # train/test split\n",
    "    from eden.util import random_bipartition_iter\n",
    "    train_global,test_global = random_bipartition_iter(graphs,train_test_split)\n",
    "\n",
    "    original_repetitions = []\n",
    "    sample_repetitions = []\n",
    "\n",
    "    for percentage in percentages:\n",
    "        originals = []\n",
    "        originals_samples = []\n",
    "        samples = []\n",
    "        for repetition in range(n_repetitions):\n",
    "            random.seed(int(313379*percentage+repetition))\n",
    "\n",
    "            train_global,train_global_ = tee(train_global)\n",
    "            test_global,test_global_ = tee(test_global)\n",
    "\n",
    "            from sklearn.linear_model import SGDClassifier\n",
    "            estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True, loss='log', n_jobs=-1)\n",
    "            local_estimator = fit(test_global_, \n",
    "                                  iterable_neg=None,\n",
    "                                  vectorizer=Vectorizer(4),\n",
    "                                  estimator=estimator, n_jobs=-1, n_iter_search=1)\n",
    "           \n",
    "            # use shuffled list to create test and sample set\n",
    "            train,train_reminder = random_bipartition_iter(train_global_,percentage)\n",
    "            train,train_ = tee(train)\n",
    "            sampled = fit_sample(train_)\n",
    "\n",
    "            #evaluate the predictive performance on held out test set\n",
    "            start=time()\n",
    "            logger.info( \"=\"*80)\n",
    "            logger.info( 'repetition: %d/%d'%(repetition+1, n_repetitions))\n",
    "            logger.info( \"training percentage:\"+str(percentage))\n",
    "            perf_orig, perf_samp = fit_and_evaluate(train, sampled, local_estimator)\n",
    "            logger.info( 'Time elapsed: %.1f sec'%((time()-start)))\n",
    "            originals.append(perf_orig)\n",
    "            samples.append(perf_samp)\n",
    "\n",
    "        original_repetitions.append(originals)\n",
    "        sample_repetitions.append(samples)\n",
    "    \n",
    "    return original_repetitions, sample_repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot(dataset, percentages, original_repetitions, sample_repetitions):\n",
    "    gc={'color':'g'}\n",
    "    rc={'color':'r'}\n",
    "    bc={'color':'b'}\n",
    "    ws = 0.02\n",
    "    o = np.mean(original_repetitions, axis=1)\n",
    "    s = np.mean(sample_repetitions, axis=1)\n",
    "    plt.figure(figsize=(18,8))\n",
    "    plt.grid()\n",
    "\n",
    "    plt.boxplot(original_repetitions, positions=percentages, widths=ws, capprops=rc, medianprops=rc, boxprops=rc, whiskerprops=rc, flierprops=rc)\n",
    "    plt.plot(percentages,o, color='r', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='r', markerfacecolor='w', label='original')\n",
    "\n",
    "    plt.boxplot(sample_repetitions, positions=percentages, widths=ws, capprops=bc, medianprops=bc, boxprops=bc, whiskerprops=bc, flierprops=bc)\n",
    "    plt.plot(percentages,s, color='b', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='b', markerfacecolor='w', label='sample')\n",
    "\n",
    "    plt.xlim(percentages[0]-.05,percentages[-1]+.05)\n",
    "    plt.title(dataset+'\\n',fontsize=17)\n",
    "    plt.legend(loc='upper right',fontsize=16)\n",
    "    plt.ylabel('Likelihood',fontsize=16)\n",
    "    plt.xlabel('Dataset size (fraction)',fontsize=16)\n",
    "    plt.savefig('%s_plot_probability_of_samples.pdf' % dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_results(result_fname,percentages, original_repetitions,sample_repetitions):\n",
    "    with open(result_fname,'w') as f:\n",
    "        f.write('dataset sizes list:\\n')\n",
    "        for perc in percentages:\n",
    "            f.write('%s '% perc)\n",
    "        f.write('\\n')\n",
    "        f.write('AUC scores:\\n')\n",
    "        for repetitions in original_repetitions,sample_repetitions:\n",
    "            f.write('%s\\n' % len(repetitions))\n",
    "            for repetition in repetitions:\n",
    "                for auc in repetition:\n",
    "                    f.write('%s ' % auc)\n",
    "                f.write('\\n')\n",
    "    \n",
    "def load_results(result_fname):\n",
    "    with open(result_fname) as f:\n",
    "        comment = next(f)\n",
    "        line = next(f)\n",
    "        percentages = [float(x) for x in line.split()]\n",
    "        comment = next(f)\n",
    "\n",
    "        original_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            original_repetitions.append(repetition)\n",
    "\n",
    "        sample_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            sample_repetitions.append(repetition)\n",
    "            \n",
    "    return percentages, original_repetitions,sample_repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setup\n",
    "dataset_names = !cat NCI60/names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with dataset: HCT_15_t\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for dataset in dataset_names:\n",
    "    #logging\n",
    "    logger = logging.getLogger()\n",
    "    if False:\n",
    "        logger_fname = '%s_probability_of_samples.log'%dataset\n",
    "    else:\n",
    "        logger_fname = None\n",
    "    configure_logging(logger,verbosity=0, filename=logger_fname)\n",
    "    \n",
    "    #main \n",
    "    start=time()\n",
    "    print( 'Working with dataset: %s' % dataset )\n",
    "    logger.info( 'Working with dataset: %s' % dataset )\n",
    "    dataset_fname = 'NCI60/' + dataset + '_orig_pos.gspan'\n",
    "    #pos_dataset_fname = 'bursi.pos.gspan'\n",
    "    \n",
    "    percentages=[.2,.4,.6,.8,.95]\n",
    "\n",
    "    original_repetitions,\\\n",
    "    sample_repetitions = evaluate(dataset_fname,\n",
    "                                  size=600,\n",
    "                                  percentages=percentages,\n",
    "                                  n_repetitions=5,\n",
    "                                  train_test_split=0.7)\n",
    "    plot(dataset, percentages, original_repetitions, sample_repetitions)\n",
    "    \n",
    "    #save and display results\n",
    "    result_fname='%s_probability_of_samples.data'%dataset\n",
    "    save_results(result_fname,percentages, original_repetitions,sample_repetitions)    \n",
    "    percentages_l, original_repetitions_l,sample_repetitions_l = load_results(result_fname)\n",
    "    plot(dataset, percentages_l, original_repetitions_l, sample_repetitions_l)\n",
    "    \n",
    "    print('Time elapsed: %s'%(datetime.timedelta(seconds=(time() - start))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#display\n",
    "for dataset in dataset_names:\n",
    "    result_fname='%s_predictive_performance_of_samples.data'%dataset\n",
    "    percentages_l, original_repetitions_l,sample_repetitions_l = load_results(result_fname)\n",
    "    plot(dataset, percentages_l, original_repetitions_l, sample_repetitions_l)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
