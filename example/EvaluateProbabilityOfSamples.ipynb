{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from eden.util import configure_logging\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import tee, chain, islice\n",
    "import numpy as np\n",
    "import random\n",
    "from time import time\n",
    "from graphlearn.graphlearn import GraphLearnSampler\n",
    "from eden.util import fit,predict\n",
    "from eden.graph import Vectorizer\n",
    "# get data\n",
    "from eden.converter.graph.gspan import gspan_to_eden\n",
    "from itertools import islice\n",
    "def get_graphs(dataset_fname, size=100):\n",
    "    return  islice(gspan_to_eden(dataset_fname),size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_sample(graphs):\n",
    "    graphs, graphs_ = tee(graphs)\n",
    "    sampler=GraphLearnSampler(radius_list=[0,1],thickness_list=[1],\n",
    "                              min_cip_count=2, min_interface_count=2,\n",
    "                              vectorizer=Vectorizer(5))\n",
    "    \n",
    "    sampler.fit(graphs, nu=0.3, n_jobs=-1)\n",
    "\n",
    "    print('graph grammar stats:')\n",
    "    interface_counts, core_counts, cip_counts = sampler.grammar().size()\n",
    "    print('#interfaces: %d   #cores: %d   #core-interface-pairs: %d' % (interface_counts, core_counts, cip_counts))\n",
    "    graphs = sampler.sample(graphs_,\n",
    "                            n_steps=5, n_samples=4,\n",
    "                            target_orig_cip=True,\n",
    "                            probabilistic_core_choice=False,\n",
    "                            score_core_choice= True,\n",
    "                            max_core_size_diff=0,\n",
    "                            generator_mode=True,\n",
    "                            improving_threshold=0.3, accept_static_penalty=0,\n",
    "                            n_jobs=-1,burnin=1,select_cip_max_tries=200,keep_duplicates=True)\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_and_evaluate(original, sampled, local_estimator):\n",
    "    outputs = []\n",
    "    for desc,train in [('original',original),\n",
    "                           ('sample',sampled)]:\n",
    "        train,train_ = tee(train)\n",
    "        size=sum(1 for x in train_)\n",
    "        print \"-\"*80\n",
    "        print 'working on %s'%(desc)\n",
    "        print 'training set sizes: #: %d'%(size)\n",
    "        if size == 0:\n",
    "            print 'WARNING: empty dataset'\n",
    "            outputs.append(0)\n",
    "        else:\n",
    "            start=time()\n",
    "            predictions = predict(train, \n",
    "                              estimator=local_estimator, \n",
    "                              vectorizer=Vectorizer(4), \n",
    "                              mode='predict_proba',\n",
    "                              n_jobs=-1)\n",
    "            avg_score=np.mean(predictions[:,1])\n",
    "            print 'avg score: %.5f' % avg_score\n",
    "            outputs.append(avg_score)\n",
    "            print 'elapsed: %.1f sec'%(time()-start)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(data_fname, size=None, percentages=None, n_repetitions=None, train_test_split=None):\n",
    "    # initializing \n",
    "    graphs = get_graphs(data_fname, size=size)\n",
    "\n",
    "    # train/test split\n",
    "    from eden.util import random_bipartition_iter\n",
    "    train_global,test_global = random_bipartition_iter(graphs,train_test_split)\n",
    "\n",
    "    original_repetitions = []\n",
    "    sample_repetitions = []\n",
    "\n",
    "    for percentage in percentages:\n",
    "        originals = []\n",
    "        originals_samples = []\n",
    "        samples = []\n",
    "        for repetition in range(n_repetitions):\n",
    "            random.seed(int(313379*percentage+repetition))\n",
    "\n",
    "            train_global,train_global_ = tee(train_global)\n",
    "            test_global,test_global_ = tee(test_global)\n",
    "\n",
    "            from sklearn.linear_model import SGDClassifier\n",
    "            estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True, loss='log', n_jobs=-1)\n",
    "            local_estimator = fit(test_global_, \n",
    "                                  iterable_neg=None,\n",
    "                                  vectorizer=Vectorizer(4),\n",
    "                                  estimator=estimator, n_jobs=-1, n_iter_search=1)\n",
    "           \n",
    "            # use shuffled list to create test and sample set\n",
    "            train,train_reminder = random_bipartition_iter(train_global_,percentage)\n",
    "            train,train_ = tee(train)\n",
    "            sampled = fit_sample(train_)\n",
    "\n",
    "            #evaluate the predictive performance on held out test set\n",
    "            start=time()\n",
    "            print \"=\"*80\n",
    "            print 'repetition: %d/%d'%(repetition+1, n_repetitions)\n",
    "            print \"training percentage:\"+str(percentage)\n",
    "            perf_orig, perf_samp = fit_and_evaluate(train, sampled, local_estimator)\n",
    "            print 'Time elapsed: %.1f sec'%((time()-start))\n",
    "            originals.append(perf_orig)\n",
    "            samples.append(perf_samp)\n",
    "\n",
    "        original_repetitions.append(originals)\n",
    "        sample_repetitions.append(samples)\n",
    "    \n",
    "    return original_repetitions, sample_repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot(dataset, percentages, original_repetitions, sample_repetitions):\n",
    "    gc={'color':'g'}\n",
    "    rc={'color':'r'}\n",
    "    bc={'color':'b'}\n",
    "    ws = 0.02\n",
    "    o = np.mean(original_repetitions, axis=1)\n",
    "    s = np.mean(sample_repetitions, axis=1)\n",
    "    plt.figure(figsize=(18,8))\n",
    "    plt.grid()\n",
    "\n",
    "    plt.boxplot(original_repetitions, positions=percentages, widths=ws, capprops=rc, medianprops=rc, boxprops=rc, whiskerprops=rc, flierprops=rc)\n",
    "    plt.plot(percentages,o, color='r', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='r', markerfacecolor='w', label='original')\n",
    "\n",
    "    plt.boxplot(sample_repetitions, positions=percentages, widths=ws, capprops=bc, medianprops=bc, boxprops=bc, whiskerprops=bc, flierprops=bc)\n",
    "    plt.plot(percentages,s, color='b', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='b', markerfacecolor='w', label='sample')\n",
    "\n",
    "    plt.xlim(percentages[0]-.05,percentages[-1]+.05)\n",
    "    plt.title(dataset+'\\n',fontsize=17)\n",
    "    plt.legend(loc='upper right',fontsize=16)\n",
    "    plt.ylabel('Likelihood',fontsize=16)\n",
    "    plt.xlabel('Dataset size (fraction)',fontsize=16)\n",
    "    plt.savefig('%s_plot_probability_of_samples.pdf' % dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with dataset: IGROV1_t\n",
      "graph grammar stats:\n",
      "#interfaces: 64   #cores: 67   #core-interface-pairs: 292\n",
      "================================================================================\n",
      "repetition: 1/7\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 84\n",
      "avg score: 0.99557\n",
      "elapsed: 1.4 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99696\n",
      "elapsed: 4.6 sec\n",
      "Time elapsed: 25.3 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 64   #cores: 67   #core-interface-pairs: 292\n",
      "================================================================================\n",
      "repetition: 2/7\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 84\n",
      "avg score: 0.99582\n",
      "elapsed: 1.2 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99739\n",
      "elapsed: 5.7 sec\n",
      "Time elapsed: 30.1 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 64   #cores: 67   #core-interface-pairs: 292\n",
      "================================================================================\n",
      "repetition: 3/7\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 84\n",
      "avg score: 0.99576\n",
      "elapsed: 1.1 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99738\n",
      "elapsed: 4.5 sec\n",
      "Time elapsed: 23.0 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 64   #cores: 67   #core-interface-pairs: 292\n",
      "================================================================================\n",
      "repetition: 4/7\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 84\n",
      "avg score: 0.99581\n",
      "elapsed: 1.1 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99637\n",
      "elapsed: 4.3 sec\n",
      "Time elapsed: 25.8 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 64   #cores: 67   #core-interface-pairs: 292\n",
      "================================================================================\n",
      "repetition: 5/7\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 84\n",
      "avg score: 0.99618\n",
      "elapsed: 1.0 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99764\n",
      "elapsed: 4.2 sec\n",
      "Time elapsed: 24.8 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 64   #cores: 67   #core-interface-pairs: 292\n",
      "================================================================================\n",
      "repetition: 6/7\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 84\n",
      "avg score: 0.99596\n",
      "elapsed: 1.1 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99696\n",
      "elapsed: 7.8 sec\n",
      "Time elapsed: 27.9 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 64   #cores: 67   #core-interface-pairs: 292\n",
      "================================================================================\n",
      "repetition: 7/7\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 84\n",
      "avg score: 0.99609\n",
      "elapsed: 1.7 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/costa/anaconda/lib/python2.7/logging/handlers.py\", line 77, in emit\n",
      "    self.doRollover()\n",
      "  File \"/Users/costa/anaconda/lib/python2.7/logging/handlers.py\", line 136, in doRollover\n",
      "    os.rename(sfn, dfn)\n",
      "OSError: [Errno 2] No such file or directory\n",
      "Logged from file graphlearn.py, line 224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg score: 0.99738\n",
      "elapsed: 4.3 sec\n",
      "Time elapsed: 29.0 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 84   #cores: 76   #core-interface-pairs: 438\n",
      "================================================================================\n",
      "repetition: 1/7\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 168\n",
      "avg score: 0.99628\n",
      "elapsed: 2.6 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 504\n",
      "avg score: 0.99713\n",
      "elapsed: 686.2 sec\n",
      "Time elapsed: 4929.6 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 84   #cores: 76   #core-interface-pairs: 438\n",
      "================================================================================\n",
      "repetition: 2/7\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 168\n",
      "avg score: 0.99617\n",
      "elapsed: 2.0 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/costa/anaconda/lib/python2.7/logging/handlers.py\", line 77, in emit\n",
      "    self.doRollover()\n",
      "  File \"/Users/costa/anaconda/lib/python2.7/logging/handlers.py\", line 136, in doRollover\n",
      "    os.rename(sfn, dfn)\n",
      "OSError: [Errno 2] No such file or directory\n",
      "Logged from file graphlearn.py, line 572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg score: 0.99706\n",
      "elapsed: 8.1 sec\n",
      "Time elapsed: 44.3 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 84   #cores: 76   #core-interface-pairs: 438\n",
      "================================================================================\n",
      "repetition: 3/7\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 168\n",
      "avg score: 0.99644\n",
      "elapsed: 2.3 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 504\n",
      "avg score: 0.99734\n",
      "elapsed: 7.7 sec\n",
      "Time elapsed: 49.5 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 84   #cores: 76   #core-interface-pairs: 438\n",
      "================================================================================\n",
      "repetition: 4/7\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 168\n",
      "avg score: 0.99600\n",
      "elapsed: 1.8 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 504\n",
      "avg score: 0.99707\n",
      "elapsed: 7.4 sec\n",
      "Time elapsed: 44.8 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 84   #cores: 76   #core-interface-pairs: 438\n",
      "================================================================================\n",
      "repetition: 5/7\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 168\n",
      "avg score: 0.99662\n",
      "elapsed: 1.6 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 504\n",
      "avg score: 0.99760\n",
      "elapsed: 8.1 sec\n",
      "Time elapsed: 50.6 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 84   #cores: 76   #core-interface-pairs: 438\n",
      "================================================================================\n",
      "repetition: 6/7\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 168\n",
      "avg score: 0.99617\n",
      "elapsed: 1.7 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 504\n",
      "avg score: 0.99709\n",
      "elapsed: 8.6 sec\n",
      "Time elapsed: 43.9 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 84   #cores: 76   #core-interface-pairs: 438\n",
      "================================================================================\n",
      "repetition: 7/7\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 168\n",
      "avg score: 0.99623\n",
      "elapsed: 2.4 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 504\n",
      "avg score: 0.99705\n",
      "elapsed: 9.2 sec\n",
      "Time elapsed: 65.5 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 112   #cores: 100   #core-interface-pairs: 583\n",
      "================================================================================\n",
      "repetition: 1/7\n",
      "training percentage:0.6\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99639\n",
      "elapsed: 3.4 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 756\n",
      "avg score: 0.99713\n",
      "elapsed: 12.3 sec\n",
      "Time elapsed: 62.6 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 112   #cores: 100   #core-interface-pairs: 583\n",
      "================================================================================\n",
      "repetition: 2/7\n",
      "training percentage:0.6\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99580\n",
      "elapsed: 2.7 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 756\n",
      "avg score: 0.99677\n",
      "elapsed: 16.4 sec\n",
      "Time elapsed: 83.3 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 112   #cores: 100   #core-interface-pairs: 583\n",
      "================================================================================\n",
      "repetition: 3/7\n",
      "training percentage:0.6\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99624\n",
      "elapsed: 3.1 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 756\n",
      "avg score: 0.99727\n",
      "elapsed: 12.9 sec\n",
      "Time elapsed: 64.6 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 112   #cores: 100   #core-interface-pairs: 583\n",
      "================================================================================\n",
      "repetition: 4/7\n",
      "training percentage:0.6\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99577\n",
      "elapsed: 2.3 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 756\n",
      "avg score: 0.99670\n",
      "elapsed: 20.4 sec\n",
      "Time elapsed: 90.7 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 112   #cores: 100   #core-interface-pairs: 583\n",
      "================================================================================\n",
      "repetition: 5/7\n",
      "training percentage:0.6\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99603\n",
      "elapsed: 3.1 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 756\n",
      "avg score: 0.99671\n",
      "elapsed: 11.2 sec\n",
      "Time elapsed: 62.3 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 112   #cores: 100   #core-interface-pairs: 583\n",
      "================================================================================\n",
      "repetition: 6/7\n",
      "training percentage:0.6\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99587\n",
      "elapsed: 3.8 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/costa/anaconda/lib/python2.7/logging/handlers.py\", line 77, in emit\n",
      "    self.doRollover()\n",
      "  File \"/Users/costa/anaconda/lib/python2.7/logging/handlers.py\", line 136, in doRollover\n",
      "    os.rename(sfn, dfn)\n",
      "OSError: [Errno 2] No such file or directory\n",
      "Logged from file graphlearn.py, line 572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg score: 0.99626\n",
      "elapsed: 21.7 sec\n",
      "Time elapsed: 78.9 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 112   #cores: 100   #core-interface-pairs: 583\n",
      "================================================================================\n",
      "repetition: 7/7\n",
      "training percentage:0.6\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99618\n",
      "elapsed: 4.3 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 756\n",
      "avg score: 0.99721\n",
      "elapsed: 11.4 sec\n",
      "Time elapsed: 66.2 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 126   #cores: 113   #core-interface-pairs: 677\n",
      "================================================================================\n",
      "repetition: 1/7\n",
      "training percentage:0.8\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 336\n",
      "avg score: 0.99611\n",
      "elapsed: 3.2 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1008\n",
      "avg score: 0.99730\n",
      "elapsed: 24.8 sec\n",
      "Time elapsed: 93.5 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 126   #cores: 113   #core-interface-pairs: 677\n",
      "================================================================================\n",
      "repetition: 2/7\n",
      "training percentage:0.8\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 336\n",
      "avg score: 0.99607\n",
      "elapsed: 6.5 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1008\n",
      "avg score: 0.99705\n",
      "elapsed: 15.2 sec\n",
      "Time elapsed: 86.7 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 126   #cores: 113   #core-interface-pairs: 677\n",
      "================================================================================\n",
      "repetition: 3/7\n",
      "training percentage:0.8\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 336\n",
      "avg score: 0.99580\n",
      "elapsed: 3.2 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/costa/anaconda/lib/python2.7/logging/handlers.py\", line 77, in emit\n",
      "  File \"/Users/costa/anaconda/lib/python2.7/logging/handlers.py\", line 77, in emit\n",
      "    self.doRollover()\n",
      "    self.doRollover()\n",
      "  File \"/Users/costa/anaconda/lib/python2.7/logging/handlers.py\", line 136, in doRollover\n",
      "  File \"/Users/costa/anaconda/lib/python2.7/logging/handlers.py\", line 136, in doRollover\n",
      "    os.rename(sfn, dfn)\n",
      "    os.rename(sfn, dfn)\n",
      "OSError: [Errno 2] No such file or directory\n",
      "OSError: [Errno 2] No such file or directory\n",
      "Logged from file graphlearn.py, line 572\n",
      "Logged from file graphlearn.py, line 572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg score: 0.99706\n",
      "elapsed: 25.7 sec\n",
      "Time elapsed: 94.0 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 126   #cores: 113   #core-interface-pairs: 677\n",
      "================================================================================\n",
      "repetition: 4/7\n",
      "training percentage:0.8\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 336\n",
      "avg score: 0.99536\n",
      "elapsed: 6.7 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1008\n",
      "avg score: 0.99622\n",
      "elapsed: 15.3 sec\n",
      "Time elapsed: 101.7 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 126   #cores: 113   #core-interface-pairs: 677\n",
      "================================================================================\n",
      "repetition: 5/7\n",
      "training percentage:0.8\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 336\n",
      "avg score: 0.99546\n",
      "elapsed: 3.6 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/costa/anaconda/lib/python2.7/logging/handlers.py\", line 77, in emit\n",
      "    self.doRollover()\n",
      "  File \"/Users/costa/anaconda/lib/python2.7/logging/handlers.py\", line 136, in doRollover\n",
      "    os.rename(sfn, dfn)\n",
      "OSError: [Errno 2] No such file or directory\n",
      "Logged from file graphlearn.py, line 572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg score: 0.99662\n",
      "elapsed: 15.8 sec\n",
      "Time elapsed: 82.8 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 126   #cores: 113   #core-interface-pairs: 677\n",
      "================================================================================\n",
      "repetition: 6/7\n",
      "training percentage:0.8\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 336\n",
      "avg score: 0.99576\n",
      "elapsed: 6.4 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1008\n",
      "avg score: 0.99608\n",
      "elapsed: 24.8 sec\n",
      "Time elapsed: 118.0 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 126   #cores: 113   #core-interface-pairs: 677\n",
      "================================================================================\n",
      "repetition: 7/7\n",
      "training percentage:0.8\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 336\n",
      "avg score: 0.99578\n",
      "elapsed: 3.7 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1008\n",
      "avg score: 0.99670\n",
      "elapsed: 16.3 sec\n",
      "Time elapsed: 82.3 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 132   #cores: 118   #core-interface-pairs: 731\n",
      "================================================================================\n",
      "repetition: 1/7\n",
      "training percentage:0.95\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 399\n",
      "avg score: 0.99577\n",
      "elapsed: 4.1 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1197\n",
      "avg score: 0.99684\n",
      "elapsed: 28.7 sec\n",
      "Time elapsed: 129.2 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 132   #cores: 118   #core-interface-pairs: 731\n",
      "================================================================================\n",
      "repetition: 2/7\n",
      "training percentage:0.95\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 399\n",
      "avg score: 0.99596\n",
      "elapsed: 4.4 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/costa/anaconda/lib/python2.7/logging/handlers.py\", line 77, in emit\n",
      "    self.doRollover()\n",
      "  File \"/Users/costa/anaconda/lib/python2.7/logging/handlers.py\", line 136, in doRollover\n",
      "    os.rename(sfn, dfn)\n",
      "OSError: [Errno 2] No such file or directory\n",
      "Logged from file graphlearn.py, line 572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg score: 0.99723\n",
      "elapsed: 17.0 sec\n",
      "Time elapsed: 94.3 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 132   #cores: 118   #core-interface-pairs: 731\n",
      "================================================================================\n",
      "repetition: 3/7\n",
      "training percentage:0.95\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 399\n",
      "avg score: 0.99536\n",
      "elapsed: 5.8 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1197\n",
      "avg score: 0.99597\n",
      "elapsed: 22.9 sec\n",
      "Time elapsed: 119.9 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 132   #cores: 118   #core-interface-pairs: 731\n",
      "================================================================================\n",
      "repetition: 4/7\n",
      "training percentage:0.95\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 399\n",
      "avg score: 0.99550\n",
      "elapsed: 6.4 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/costa/anaconda/lib/python2.7/logging/handlers.py\", line 77, in emit\n",
      "  File \"/Users/costa/anaconda/lib/python2.7/logging/handlers.py\", line 77, in emit\n",
      "    self.doRollover()\n",
      "    self.doRollover()\n",
      "  File \"/Users/costa/anaconda/lib/python2.7/logging/handlers.py\", line 136, in doRollover\n",
      "  File \"/Users/costa/anaconda/lib/python2.7/logging/handlers.py\", line 135, in doRollover\n",
      "    os.rename(sfn, dfn)\n",
      "    os.remove(dfn)\n",
      "OSError: [Errno 2] No such file or directory\n",
      "OSError: [Errno 2] No such file or directory: '/Users/costa/Desktop/BTSync/Projects/graphlearn/example/IGROV1_t_probability_of_samples.log.10'\n",
      "Logged from file graphlearn.py, line 572\n",
      "Logged from file graphlearn.py, line 572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg score: 0.99711\n",
      "elapsed: 17.5 sec\n",
      "Time elapsed: 95.6 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 132   #cores: 118   #core-interface-pairs: 731\n",
      "================================================================================\n",
      "repetition: 5/7\n",
      "training percentage:0.95\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 399\n",
      "avg score: 0.99561\n",
      "elapsed: 3.4 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1197\n",
      "avg score: 0.99699\n",
      "elapsed: 22.1 sec\n",
      "Time elapsed: 100.9 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 132   #cores: 118   #core-interface-pairs: 731\n",
      "================================================================================\n",
      "repetition: 6/7\n",
      "training percentage:0.95\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 399\n",
      "avg score: 0.99563\n",
      "elapsed: 7.2 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1197\n",
      "avg score: 0.99647\n",
      "elapsed: 31.0 sec\n",
      "Time elapsed: 147.4 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 132   #cores: 118   #core-interface-pairs: 731\n",
      "================================================================================\n",
      "repetition: 7/7\n",
      "training percentage:0.95\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 399\n",
      "avg score: 0.99574\n",
      "elapsed: 3.8 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1197\n",
      "avg score: 0.99679\n",
      "elapsed: 16.6 sec\n",
      "Time elapsed: 93.9 sec\n",
      "CPU times: user 16min 24s, sys: 2min 21s, total: 18min 45s\n",
      "Wall time: 2h 19min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#experiment\n",
    "\n",
    "dataset_names = !cat NCI60/names\n",
    "for dataset in dataset_names:\n",
    "    print 'Working with dataset: %s' % dataset \n",
    "    dataset_fname = 'NCI60/' + dataset + '_orig_pos.gspan'\n",
    "    #dataset_fname = 'bursi.pos.gspan'\n",
    "\n",
    "    configure_logging(logging.getLogger(),verbosity=1, filename='%s_probability_of_samples.log'%dataset)\n",
    "\n",
    "    percentages=[.05,.2,.4,.6,.8,.95]\n",
    "\n",
    "    original_repetitions,\\\n",
    "    sample_repetitions = evaluate(dataset_fname,\n",
    "                                  size=600,\n",
    "                                  percentages=percentages,\n",
    "                                  n_repetitions=5,\n",
    "                                  train_test_split=0.7)\n",
    "    plot(dataset, percentages, original_repetitions, sample_repetitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
