{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from eden.util import configure_logging\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import tee, chain, islice\n",
    "import numpy as np\n",
    "import random\n",
    "from time import time\n",
    "import datetime\n",
    "from graphlearn.graphlearn import GraphLearnSampler\n",
    "from eden.util import fit,predict\n",
    "from eden.graph import Vectorizer\n",
    "# get data\n",
    "from eden.converter.graph.gspan import gspan_to_eden\n",
    "from itertools import islice\n",
    "def get_graphs(dataset_fname, size=100):\n",
    "    return  islice(gspan_to_eden(dataset_fname),size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_sample(graphs):\n",
    "    graphs, graphs_ = tee(graphs)\n",
    "    sampler=GraphLearnSampler(radius_list=[0,1],thickness_list=[1],\n",
    "                              min_cip_count=2, min_interface_count=2,\n",
    "                              vectorizer=Vectorizer(5))\n",
    "    \n",
    "    sampler.fit(graphs, nu=0.5, n_jobs=-1)\n",
    "\n",
    "    logger.info('graph grammar stats:')\n",
    "    interface_counts, core_counts, cip_counts = sampler.grammar().size()\n",
    "    logger.info('#interfaces: %d   #cores: %d   #core-interface-pairs: %d' % (interface_counts, core_counts, cip_counts))\n",
    "    graphs = sampler.sample(graphs_,\n",
    "                            n_steps=10, n_samples=4,\n",
    "                            target_orig_cip=True,\n",
    "                            probabilistic_core_choice=False,\n",
    "                            score_core_choice= False,\n",
    "                            max_core_size_diff=0,\n",
    "                            burnin=1,\n",
    "                            omit_seed=True,\n",
    "                            generator_mode=True,\n",
    "                            improving_threshold=0.3, \n",
    "                            accept_static_penalty=0,\n",
    "                            n_jobs=-1,\n",
    "                            select_cip_max_tries=200,\n",
    "                            keep_duplicates=True)\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_and_evaluate(original, sampled, local_estimator):\n",
    "    outputs = []\n",
    "    for desc,train in [('original',original),\n",
    "                           ('sample',sampled)]:\n",
    "        train,train_ = tee(train)\n",
    "        size=sum(1 for x in train_)\n",
    "        logger.info( \"-\"*80)\n",
    "        logger.info( 'working on %s'%(desc))\n",
    "        logger.info( 'training set sizes: #: %d'%(size))\n",
    "        if size == 0:\n",
    "            logger.info( 'WARNING: empty dataset')\n",
    "            outputs.append(0)\n",
    "        else:\n",
    "            start=time()\n",
    "            predictions = predict(train, \n",
    "                              estimator=local_estimator, \n",
    "                              vectorizer=Vectorizer(4), \n",
    "                              mode='predict_proba',\n",
    "                              n_jobs=-1)\n",
    "            avg_score=np.mean(predictions[:,1])\n",
    "            logger.info( 'avg score: %.5f' % avg_score)\n",
    "            outputs.append(avg_score)\n",
    "            logger.info( 'elapsed: %.1f sec'%(time()-start))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(data_fname, size=None, percentages=None, n_repetitions=None, train_test_split=None):\n",
    "    # initializing \n",
    "    graphs = get_graphs(data_fname, size=size)\n",
    "\n",
    "    # train/test split\n",
    "    from eden.util import random_bipartition_iter\n",
    "    train_global,test_global = random_bipartition_iter(graphs,train_test_split)\n",
    "\n",
    "    original_repetitions = []\n",
    "    sample_repetitions = []\n",
    "\n",
    "    for percentage in percentages:\n",
    "        originals = []\n",
    "        originals_samples = []\n",
    "        samples = []\n",
    "        for repetition in range(n_repetitions):\n",
    "            random.seed(int(313379*percentage+repetition))\n",
    "\n",
    "            train_global,train_global_ = tee(train_global)\n",
    "            test_global,test_global_ = tee(test_global)\n",
    "\n",
    "            from sklearn.linear_model import SGDClassifier\n",
    "            estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True, loss='log', n_jobs=-1)\n",
    "            local_estimator = fit(test_global_, \n",
    "                                  iterable_neg=None,\n",
    "                                  vectorizer=Vectorizer(4),\n",
    "                                  estimator=estimator, n_jobs=-1, n_iter_search=1)\n",
    "           \n",
    "            # use shuffled list to create test and sample set\n",
    "            train,train_reminder = random_bipartition_iter(train_global_,percentage)\n",
    "            train,train_ = tee(train)\n",
    "            sampled = fit_sample(train_)\n",
    "\n",
    "            #evaluate the predictive performance on held out test set\n",
    "            start=time()\n",
    "            logger.info( \"=\"*80)\n",
    "            logger.info( 'repetition: %d/%d'%(repetition+1, n_repetitions))\n",
    "            logger.info( \"training percentage:\"+str(percentage))\n",
    "            perf_orig, perf_samp = fit_and_evaluate(train, sampled, local_estimator)\n",
    "            logger.info( 'Time elapsed: %.1f sec'%((time()-start)))\n",
    "            originals.append(perf_orig)\n",
    "            samples.append(perf_samp)\n",
    "\n",
    "        original_repetitions.append(originals)\n",
    "        sample_repetitions.append(samples)\n",
    "    \n",
    "    return original_repetitions, sample_repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot(dataset, percentages, original_repetitions, sample_repetitions):\n",
    "    gc={'color':'g'}\n",
    "    rc={'color':'r'}\n",
    "    bc={'color':'b'}\n",
    "    ws = 0.02\n",
    "    o = np.mean(original_repetitions, axis=1)\n",
    "    s = np.mean(sample_repetitions, axis=1)\n",
    "    plt.figure(figsize=(18,8))\n",
    "    plt.grid()\n",
    "\n",
    "    plt.boxplot(original_repetitions, positions=percentages, widths=ws, capprops=rc, medianprops=rc, boxprops=rc, whiskerprops=rc, flierprops=rc)\n",
    "    plt.plot(percentages,o, color='r', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='r', markerfacecolor='w', label='original')\n",
    "\n",
    "    plt.boxplot(sample_repetitions, positions=percentages, widths=ws, capprops=bc, medianprops=bc, boxprops=bc, whiskerprops=bc, flierprops=bc)\n",
    "    plt.plot(percentages,s, color='b', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='b', markerfacecolor='w', label='sample')\n",
    "\n",
    "    plt.xlim(percentages[0]-.05,percentages[-1]+.05)\n",
    "    plt.title(dataset+'\\n',fontsize=17)\n",
    "    plt.legend(loc='upper right',fontsize=16)\n",
    "    plt.ylabel('Likelihood',fontsize=16)\n",
    "    plt.xlabel('Dataset size (fraction)',fontsize=16)\n",
    "    plt.savefig('%s_plot_probability_of_samples.pdf' % dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_results(result_fname,percentages, original_repetitions,sample_repetitions):\n",
    "    with open(result_fname,'w') as f:\n",
    "        f.write('dataset sizes list:\\n')\n",
    "        for perc in percentages:\n",
    "            f.write('%s '% perc)\n",
    "        f.write('\\n')\n",
    "        f.write('AUC scores:\\n')\n",
    "        for repetitions in original_repetitions,sample_repetitions:\n",
    "            f.write('%s\\n' % len(repetitions))\n",
    "            for repetition in repetitions:\n",
    "                for auc in repetition:\n",
    "                    f.write('%s ' % auc)\n",
    "                f.write('\\n')\n",
    "    \n",
    "def load_results(result_fname):\n",
    "    with open(result_fname) as f:\n",
    "        comment = next(f)\n",
    "        line = next(f)\n",
    "        percentages = [float(x) for x in line.split()]\n",
    "        comment = next(f)\n",
    "\n",
    "        original_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            original_repetitions.append(repetition)\n",
    "\n",
    "        sample_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            sample_repetitions.append(repetition)\n",
    "            \n",
    "    return percentages, original_repetitions,sample_repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setup\n",
    "dataset_names = !cat NCI60/names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with dataset: HS_578T_t\n",
      "Working with dataset: HS_578T_t\n",
      "graph grammar stats:\n",
      "#interfaces: 57   #cores: 67   #core-interface-pairs: 269\n",
      "================================================================================\n",
      "repetition: 1/3\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 84\n",
      "avg score: 0.99494\n",
      "elapsed: 0.9 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 249\n",
      "avg score: 0.99683\n",
      "elapsed: 3.1 sec\n",
      "Time elapsed: 29.0 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 57   #cores: 67   #core-interface-pairs: 269\n",
      "================================================================================\n",
      "repetition: 2/3\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 84\n",
      "avg score: 0.99506\n",
      "elapsed: 0.9 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 249\n",
      "avg score: 0.99710\n",
      "elapsed: 3.2 sec\n",
      "Time elapsed: 30.4 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 57   #cores: 67   #core-interface-pairs: 269\n",
      "================================================================================\n",
      "repetition: 3/3\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 84\n",
      "avg score: 0.99480\n",
      "elapsed: 0.9 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 249\n",
      "avg score: 0.99676\n",
      "elapsed: 3.2 sec\n",
      "Time elapsed: 31.3 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 79   #cores: 86   #core-interface-pairs: 418\n",
      "================================================================================\n",
      "repetition: 1/3\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 168\n",
      "avg score: 0.99449\n",
      "elapsed: 1.5 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 498\n",
      "avg score: 0.99683\n",
      "elapsed: 5.1 sec\n",
      "Time elapsed: 56.4 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 79   #cores: 86   #core-interface-pairs: 418\n",
      "================================================================================\n",
      "repetition: 2/3\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 168\n",
      "avg score: 0.99419\n",
      "elapsed: 1.5 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 498\n",
      "avg score: 0.99655\n",
      "elapsed: 5.1 sec\n",
      "Time elapsed: 61.7 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 79   #cores: 86   #core-interface-pairs: 418\n",
      "================================================================================\n",
      "repetition: 3/3\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 168\n",
      "avg score: 0.99363\n",
      "elapsed: 1.4 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 498\n",
      "avg score: 0.99647\n",
      "elapsed: 5.2 sec\n",
      "Time elapsed: 59.3 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 98   #cores: 102   #core-interface-pairs: 544\n",
      "================================================================================\n",
      "repetition: 1/3\n",
      "training percentage:0.6\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99264\n",
      "elapsed: 2.5 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 747\n",
      "avg score: 0.99746\n",
      "elapsed: 8.5 sec\n",
      "Time elapsed: 84.0 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 98   #cores: 102   #core-interface-pairs: 544\n",
      "================================================================================\n",
      "repetition: 2/3\n",
      "training percentage:0.6\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99240\n",
      "elapsed: 2.4 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 747\n",
      "avg score: 0.99645\n",
      "elapsed: 9.0 sec\n",
      "Time elapsed: 92.1 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 98   #cores: 102   #core-interface-pairs: 544\n",
      "================================================================================\n",
      "repetition: 3/3\n",
      "training percentage:0.6\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99260\n",
      "elapsed: 2.5 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 747\n",
      "avg score: 0.99658\n",
      "elapsed: 9.0 sec\n",
      "Time elapsed: 84.4 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 117   #cores: 114   #core-interface-pairs: 652\n",
      "================================================================================\n",
      "repetition: 1/3\n",
      "training percentage:0.8\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 336\n",
      "avg score: 0.99320\n",
      "elapsed: 3.0 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1002\n",
      "avg score: 0.99632\n",
      "elapsed: 11.7 sec\n",
      "Time elapsed: 117.8 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 117   #cores: 114   #core-interface-pairs: 652\n",
      "================================================================================\n",
      "repetition: 2/3\n",
      "training percentage:0.8\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 336\n",
      "avg score: 0.99335\n",
      "elapsed: 3.2 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1002\n",
      "avg score: 0.99572\n",
      "elapsed: 11.5 sec\n",
      "Time elapsed: 122.8 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 117   #cores: 114   #core-interface-pairs: 652\n",
      "================================================================================\n",
      "repetition: 3/3\n",
      "training percentage:0.8\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 336\n",
      "avg score: 0.99308\n",
      "elapsed: 3.4 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1002\n",
      "avg score: 0.99585\n",
      "elapsed: 11.7 sec\n",
      "Time elapsed: 119.7 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 128   #cores: 121   #core-interface-pairs: 725\n",
      "================================================================================\n",
      "repetition: 1/3\n",
      "training percentage:0.95\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 399\n",
      "avg score: 0.99368\n",
      "elapsed: 3.7 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1191\n",
      "avg score: 0.99600\n",
      "elapsed: 16.4 sec\n",
      "Time elapsed: 170.8 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 128   #cores: 121   #core-interface-pairs: 725\n",
      "================================================================================\n",
      "repetition: 2/3\n",
      "training percentage:0.95\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 399\n",
      "avg score: 0.99349\n",
      "elapsed: 3.8 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1191\n",
      "avg score: 0.99590\n",
      "elapsed: 12.5 sec\n",
      "Time elapsed: 134.8 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 128   #cores: 121   #core-interface-pairs: 725\n",
      "================================================================================\n",
      "repetition: 3/3\n",
      "training percentage:0.95\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 399\n",
      "avg score: 0.99330\n",
      "elapsed: 3.1 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 1191\n",
      "avg score: 0.99623\n",
      "elapsed: 13.4 sec\n",
      "Time elapsed: 121.6 sec\n",
      "Time elapsed: 0:27:26.974741\n",
      "Working with dataset: HT29_t\n",
      "Working with dataset: HT29_t\n",
      "graph grammar stats:\n",
      "#interfaces: 61   #cores: 70   #core-interface-pairs: 294\n",
      "================================================================================\n",
      "repetition: 1/3\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 84\n",
      "avg score: 0.99235\n",
      "elapsed: 0.9 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99245\n",
      "elapsed: 3.4 sec\n",
      "Time elapsed: 35.3 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 61   #cores: 70   #core-interface-pairs: 294\n",
      "================================================================================\n",
      "repetition: 2/3\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 84\n",
      "avg score: 0.99212\n",
      "elapsed: 0.9 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99241\n",
      "elapsed: 4.5 sec\n",
      "Time elapsed: 43.9 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 61   #cores: 70   #core-interface-pairs: 294\n",
      "================================================================================\n",
      "repetition: 3/3\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 84\n",
      "avg score: 0.99196\n",
      "elapsed: 1.7 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 252\n",
      "avg score: 0.99495\n",
      "elapsed: 3.7 sec\n",
      "Time elapsed: 56.8 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 93   #cores: 91   #core-interface-pairs: 464\n",
      "================================================================================\n",
      "repetition: 1/3\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 168\n",
      "avg score: 0.99471\n",
      "elapsed: 1.3 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 504\n",
      "avg score: 0.99505\n",
      "elapsed: 4.9 sec\n",
      "Time elapsed: 59.0 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 93   #cores: 91   #core-interface-pairs: 464\n",
      "================================================================================\n",
      "repetition: 2/3\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 168\n",
      "avg score: 0.99382\n",
      "elapsed: 1.4 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 504\n",
      "avg score: 0.99465\n",
      "elapsed: 5.1 sec\n",
      "Time elapsed: 58.2 sec\n",
      "graph grammar stats:\n",
      "#interfaces: 93   #cores: 91   #core-interface-pairs: 464\n",
      "================================================================================\n",
      "repetition: 3/3\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #: 168\n",
      "avg score: 0.99400\n",
      "elapsed: 1.5 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #: 504\n",
      "avg score: 0.99346\n",
      "elapsed: 6.1 sec\n",
      "Time elapsed: 63.7 sec\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for dataset in dataset_names[4:]:\n",
    "    #logging\n",
    "    logger = logging.getLogger()\n",
    "    if True:\n",
    "        logger_fname = '%s_probability_of_samples.log'%dataset\n",
    "    else:\n",
    "        logger_fname = None\n",
    "    configure_logging(logger,verbosity=1, filename=logger_fname)\n",
    "    \n",
    "    #main \n",
    "    start=time()\n",
    "    print('*'*80)\n",
    "    print( 'Working with dataset: %s' % dataset )\n",
    "    logger.info( 'Working with dataset: %s' % dataset )\n",
    "    dataset_fname = 'NCI60/' + dataset + '_orig_pos.gspan'\n",
    "    #pos_dataset_fname = 'bursi.pos.gspan'\n",
    "    \n",
    "    percentages=[.2,.4,.6,.8,.95]\n",
    "\n",
    "    original_repetitions,\\\n",
    "    sample_repetitions = evaluate(dataset_fname,\n",
    "                                  size=600,\n",
    "                                  percentages=percentages,\n",
    "                                  n_repetitions=3,\n",
    "                                  train_test_split=0.7)\n",
    "    plot(dataset, percentages, original_repetitions, sample_repetitions)\n",
    "    \n",
    "    #save and display results\n",
    "    result_fname='%s_probability_of_samples.data'%dataset\n",
    "    save_results(result_fname,percentages, original_repetitions,sample_repetitions)    \n",
    "    percentages_l, original_repetitions_l,sample_repetitions_l = load_results(result_fname)\n",
    "    plot(dataset, percentages_l, original_repetitions_l, sample_repetitions_l)\n",
    "    \n",
    "    print('Time elapsed: %s'%(datetime.timedelta(seconds=(time() - start))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#display\n",
    "for dataset in dataset_names:\n",
    "    result_fname='%s_predictive_performance_of_samples.data'%dataset\n",
    "    percentages_l, original_repetitions_l,sample_repetitions_l = load_results(result_fname)\n",
    "    plot(dataset, percentages_l, original_repetitions_l, sample_repetitions_l)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
