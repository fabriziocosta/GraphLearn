{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import eden\n",
    "import matplotlib.pyplot as plt\n",
    "from eden.util import configure_logging\n",
    "import logging\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import tee, chain, islice\n",
    "import numpy as np\n",
    "import random\n",
    "from time import time\n",
    "import datetime\n",
    "from graphlearn.graphlearn import GraphLearnSampler\n",
    "from eden.util import fit,estimate\n",
    "from eden.graph import Vectorizer\n",
    "# get data\n",
    "from eden.converter.graph.gspan import gspan_to_eden\n",
    "from eden.converter.molecule.obabel import mol_file_to_iterable\n",
    "from eden.converter.molecule.obabel import obabel_to_eden\n",
    "from itertools import islice\n",
    "\n",
    "def get_graphs(dataset_fname, size=None):\n",
    "    iterable = mol_file_to_iterable(dataset_fname, file_format='smi')\n",
    "    graphs = obabel_to_eden(iterable, file_format='smi')\n",
    "    return islice(graphs,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rename to pre_processor and expose all relevant parameters for optimization\n",
    "\n",
    "def generate_sample(graphs,\n",
    "                    random_state=42,\n",
    "                    complexity=5,\n",
    "                    nu=0.25,\n",
    "                    radius_list=[0,1],\n",
    "                    thickness_list=[2,3],\n",
    "                    n_steps=5,\n",
    "                    n_samples=4,\n",
    "                    burnin=1,\n",
    "                    improving_threshold=0.25,\n",
    "                    max_core_size_diff=3):\n",
    "    graphs, graphs_ = tee(graphs)\n",
    "    sampler=GraphLearnSampler(radius_list=radius_list,thickness_list=thickness_list,\n",
    "                              min_cip_count=2, min_interface_count=2,\n",
    "                              vectorizer=Vectorizer(complexity), random_state=random_state)\n",
    "    \n",
    "    sampler.fit(graphs, nu=nu, n_jobs=-1)\n",
    "\n",
    "    logger.info('graph grammar stats:')\n",
    "    dataset_size, interface_counts, core_counts, cip_counts = sampler.grammar().size()\n",
    "    logger.info('#instances:%d   #interfaces: %d   #cores: %d   #core-interface-pairs: %d' % (dataset_size, interface_counts, core_counts, cip_counts))\n",
    "    graphs = sampler.sample(graphs_,\n",
    "                            n_steps=n_steps, \n",
    "                            n_samples=n_samples,\n",
    "                            target_orig_cip=True,\n",
    "                            probabilistic_core_choice=False,\n",
    "                            score_core_choice= False,\n",
    "                            max_core_size_diff=max_core_size_diff,\n",
    "                            burnin=burnin,\n",
    "                            omit_seed=True,\n",
    "                            max_cycle_size=6,\n",
    "                            improving_threshold=improving_threshold,\n",
    "                            accept_static_penalty=0,\n",
    "                            n_jobs=-1,\n",
    "                            select_cip_max_tries=200,\n",
    "                            keep_duplicates=False,\n",
    "                            generator_mode=True)\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def constructive_model(pos_fname, neg_fname, size=None, model_fname=None, n_iter=40, train_test_split=0.7, random_state=42):\n",
    "    def pre_processor( graphs, **args):\n",
    "        graphs = generate_sample(graphs, **args)\n",
    "        return graphs\n",
    "    \n",
    "    from eden.graph import Vectorizer\n",
    "    vectorizer = Vectorizer()\n",
    "\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    estimator = SGDClassifier(average=True, class_weight='auto', shuffle=True)\n",
    "\n",
    "    #create iterable from files\n",
    "    iterable_pos= get_graphs(pos_fname, size=size)\n",
    "    iterable_neg= get_graphs(neg_fname, size=size)\n",
    "\n",
    "\n",
    "    from itertools import tee\n",
    "    iterable_pos, iterable_pos_ = tee(iterable_pos)\n",
    "    iterable_neg, iterable_neg_ = tee(iterable_neg)\n",
    "    \n",
    "    import time\n",
    "    start = time.time()\n",
    "    logger.info('-'*80)\n",
    "    logger.info('Dataset')\n",
    "    logger.info('# positives: %d  # negatives: %d (%.1f sec %s)'%(sum(1 for x in iterable_pos_), sum(1 for x in iterable_neg_), time.time() - start, str(datetime.timedelta(seconds=(time.time() - start)))))\n",
    "    \n",
    "    #split train/test\n",
    "    from eden.util import random_bipartition_iter\n",
    "    iterable_pos_train, iterable_pos_test = random_bipartition_iter(iterable_pos, relative_size=train_test_split)\n",
    "    iterable_neg_train, iterable_neg_test = random_bipartition_iter(iterable_neg, relative_size=train_test_split)\n",
    "\n",
    "\n",
    "\n",
    "    #make predictive model\n",
    "    #NOTE: since parallelization cannot happen in a nested way, and since the graph learn already parallelize, we avoid \n",
    "    from eden.model import ActiveLearningBinaryClassificationModel\n",
    "    model = ActiveLearningBinaryClassificationModel(pre_processor,\n",
    "                                                    estimator=estimator,\n",
    "                                                    vectorizer=vectorizer,\n",
    "                                                    pre_processor_n_jobs=1,\n",
    "                                                    random_state=random_state)\n",
    "\n",
    "    #optimize hyperparameters and fit model\n",
    "    from numpy.random import randint\n",
    "    from numpy.random import uniform\n",
    "\n",
    "    pre_processor_parameters={'complexity':[3,5],\n",
    "                              'nu':[0.1,0.25,0.33,0.5],\n",
    "                              'radius_list':[[0,1,2]],\n",
    "                              'thickness_list':[[1,2],[2],[2,3]],\n",
    "                              'n_steps':[5,7,9],\n",
    "                              'n_samples':[2,4],\n",
    "                              'burnin':[0,1,2],\n",
    "                              'improving_threshold':[0.25,0.33,0.5],\n",
    "                              'max_core_size_diff':[0,1,2,3],\n",
    "                              'random_state':[random_state]} \n",
    "\n",
    "    vectorizer_parameters={'complexity':[3,4,5]}\n",
    "\n",
    "    estimator_parameters={'n_iter':randint(5, 100, size=n_iter),\n",
    "                          'penalty':['l1','l2','elasticnet'],\n",
    "                          'l1_ratio':uniform(0.1,0.9, size=n_iter), \n",
    "                          'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "                          'power_t':uniform(0.1, size=n_iter),\n",
    "                          'alpha': [10**x for x in range(-8,-2)],\n",
    "                          'eta0': [10**x for x in range(-4,-1)],\n",
    "                          'learning_rate': [\"invscaling\", \"constant\", \"optimal\"]}\n",
    "\n",
    "    logger.info('-'*80)\n",
    "    logger.info('Choosing from parameters:')\n",
    "    from eden.util import serialize_dict\n",
    "    logger.info(serialize_dict(pre_processor_parameters))\n",
    "    logger.info(serialize_dict(vectorizer_parameters))\n",
    "    logger.info(serialize_dict(estimator_parameters))\n",
    "    logger.info('-'*80)\n",
    "\n",
    "    model.optimize(iterable_pos_train, iterable_neg_train, \n",
    "                   model_name=model_fname,\n",
    "                   n_iter=n_iter,\n",
    "                   pre_processor_parameters=pre_processor_parameters, \n",
    "                   vectorizer_parameters=vectorizer_parameters, \n",
    "                   estimator_parameters=estimator_parameters)\n",
    "  \n",
    "    #estimate predictive performance on original data, i.e. without sampling\n",
    "    logger.info('-'*80)\n",
    "    logger.info('Parameters:')\n",
    "    opt_params = model.get_parameters()\n",
    "    logger.info(opt_params)\n",
    "    opt_vectorizer = model.get_vectorizer()\n",
    "    opt_estimator = model.get_estimator()\n",
    "    from eden.util import estimate\n",
    "    apr, roc = estimate(iterable_pos_test, iterable_neg_test,\n",
    "                        estimator=opt_estimator,\n",
    "                        vectorizer=opt_vectorizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Experimental pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "configure_logging(logger,verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Dataset\n",
      "# positives: 200  # negatives: 200 (0.3 sec 0:00:00.306129)\n",
      "--------------------------------------------------------------------------------\n",
      "Choosing from parameters:\n",
      "    burnin: [0, 1, 2]\n",
      "complexity: [3, 5]\n",
      "improving_threshold: [0.25, 0.33, 0.5]\n",
      "max_core_size_diff: [0, 1, 2, 3]\n",
      " n_samples: [2, 4]\n",
      "   n_steps: [5, 7, 9]\n",
      "        nu: [0.1, 0.25, 0.33, 0.5]\n",
      "radius_list: [[0, 1, 2]]\n",
      "random_state: [2]\n",
      "thickness_list: [[1, 2], [2], [2, 3]]\n",
      "complexity: [3, 4, 5]\n",
      "     alpha: [1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001]\n",
      "      eta0: [0.0001, 0.001, 0.01]\n",
      "  l1_ratio: [ 0.31246886  0.56769089  0.14766148  0.43874078  0.86867181  0.37064723\n",
      "  0.406477    0.33693454  0.54560713  0.1560296   0.7785867   0.27993394\n",
      "  0.56328043  0.41195084  0.66254261  0.49290766  0.62098001  0.61171872\n",
      "  0.63882845  0.7668905   0.68173755  0.65347872  0.51550808  0.28036526\n",
      "  0.66254283  0.21045886  0.24640558  0.18052233  0.21385312  0.58166914\n",
      "  0.62188071  0.72052123  0.69775508  0.2320831   0.41381769  0.16556153\n",
      "  0.20199773  0.37049483  0.16240002  0.25522952]\n",
      "learning_rate: ['invscaling', 'constant', 'optimal']\n",
      "      loss: ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']\n",
      "    n_iter: [29 64  8 36 15 82 82 77 17 12 10 38 93 68 13 97 43 35  5 27 13 21 37 36 95\n",
      " 59  8 12 86 26 73 35 17 14  7 53 35 41 47 44]\n",
      "   penalty: ['l1', 'l2', 'elasticnet']\n",
      "   power_t: [ 0.13498227  0.88700743  0.47329674  0.39888446  0.45619738  0.29082095\n",
      "  0.14021311  0.62115829  0.2965092   0.43765629  0.14485034  0.54057227\n",
      "  0.57732231  0.56346277  0.95517917  0.48152365  0.66515637  0.9519581\n",
      "  0.3734739   0.14507125  0.44499049  0.36388989  0.99803888  0.20780038\n",
      "  0.13921404  0.70299443  0.63256569  0.14144979  0.7685012   0.87532202\n",
      "  0.8967954   0.89671021  0.60272437  0.51446809  0.17310581  0.6590742\n",
      "  0.53393811  0.93898402  0.72681932  0.82765027]\n",
      "--------------------------------------------------------------------------------\n",
      "graph grammar stats:\n",
      "#instances:100   #interfaces: 151   #cores: 193   #core-interface-pairs: 560\n",
      "graph grammar stats:\n",
      "#instances:100   #interfaces: 208   #cores: 203   #core-interface-pairs: 775\n",
      "\n",
      "\n",
      "\tIteration: 1/40 (after 61.4 sec; 0:01:01.351543)\n",
      "Best score (roc_auc): 0.686 (0.831 +- 0.145)\n",
      "\n",
      "Data:\n",
      "Instances: 83 ; Features: 1048577 with an avg of 199 features\n",
      "class: 1 count:37 (0.45)\tclass: -1 count:46 (0.55)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "    burnin: 0\n",
      "complexity: 3\n",
      "improving_threshold: 0.25\n",
      "max_core_size_diff: 0\n",
      " n_samples: 2\n",
      "   n_steps: 5\n",
      "        nu: 0.1\n",
      "radius_list: [0, 1, 2]\n",
      "random_state: 2\n",
      "thickness_list: [1, 2]\n",
      "\n",
      "Vectorizer:\n",
      "complexity: 3\n",
      "\n",
      "Estimator:\n",
      "     alpha: 1e-08\n",
      "      eta0: 0.01\n",
      "  l1_ratio: 0.246405576265\n",
      "learning_rate: invscaling\n",
      "      loss: squared_hinge\n",
      "    n_iter: 41\n",
      "   penalty: elasticnet\n",
      "   power_t: 0.398884464812\n",
      "\n",
      "\n",
      "\tIteration: 1/40 (after 62.7 sec; 0:01:02.705226)\n",
      "Best score (roc_auc): 0.797 (0.897 +- 0.099)\n",
      "\n",
      "Data:\n",
      "Instances: 83 ; Features: 1048577 with an avg of 199 features\n",
      "class: 1 count:37 (0.45)\tclass: -1 count:46 (0.55)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "    burnin: 0\n",
      "complexity: 3\n",
      "improving_threshold: 0.25\n",
      "max_core_size_diff: 0\n",
      " n_samples: 2\n",
      "   n_steps: 5\n",
      "        nu: 0.1\n",
      "radius_list: [0, 1, 2]\n",
      "random_state: 2\n",
      "thickness_list: [1, 2]\n",
      "\n",
      "Vectorizer:\n",
      "complexity: 3\n",
      "\n",
      "Estimator:\n",
      "     alpha: 1e-05\n",
      "      eta0: 0.001\n",
      "  l1_ratio: 0.21385312221\n",
      "learning_rate: optimal\n",
      "      loss: log\n",
      "    n_iter: 95\n",
      "   penalty: l2\n",
      "   power_t: 0.140213110465\n",
      "graph grammar stats:\n",
      "#instances:100   #interfaces: 103   #cores: 92   #core-interface-pairs: 274\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pos_fname='bursi_pos_orig.smi'\n",
    "neg_fname='bursi_neg_orig.smi'\n",
    "model = constructive_model(pos_fname, neg_fname, size=200, model_fname='bursi',\n",
    "                           n_iter=40, train_test_split=0.5, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# positives: 100  # negatives: 100 (0.2 sec 0:00:00.176622)\n",
      "graph grammar stats:\n",
      "#instances:50   #interfaces: 36   #cores: 53   #core-interface-pairs: 119\n",
      "graph grammar stats:\n",
      "#instances:50   #interfaces: 41   #cores: 53   #core-interface-pairs: 137\n",
      "\n",
      "\n",
      "\tIteration: 1/5 (after 38.4 sec; 0:00:38.413056)\n",
      "Best score (roc_auc): 0.729 (0.862 +- 0.133)\n",
      "\n",
      "Data:\n",
      "Instances: 187 ; Features: 1048577 with an avg of 379 features\n",
      "class: 1 count:91 (0.49)\tclass: -1 count:96 (0.51)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "    burnin: 1\n",
      "complexity: 5\n",
      "improving_threshold: 0.25\n",
      "max_core_size_diff: 0\n",
      " n_samples: 4\n",
      "   n_steps: 5\n",
      "        nu: 0.1\n",
      "radius_list: [0, 1]\n",
      "random_state: 42\n",
      "thickness_list: [1]\n",
      "\n",
      "Vectorizer:\n",
      "complexity: 4\n",
      "\n",
      "Estimator:\n",
      "     alpha: 1e-07\n",
      "      eta0: 0.01\n",
      "  l1_ratio: 0.698057935388\n",
      "learning_rate: invscaling\n",
      "      loss: squared_hinge\n",
      "    n_iter: 36\n",
      "   penalty: l2\n",
      "   power_t: 0.193562877926\n",
      "\n",
      "\n",
      "\tIteration: 1/5 (after 43.2 sec; 0:00:43.201064)\n",
      "Best score (roc_auc): 0.746 (0.894 +- 0.148)\n",
      "\n",
      "Data:\n",
      "Instances: 187 ; Features: 1048577 with an avg of 379 features\n",
      "class: 1 count:91 (0.49)\tclass: -1 count:96 (0.51)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "    burnin: 1\n",
      "complexity: 5\n",
      "improving_threshold: 0.25\n",
      "max_core_size_diff: 0\n",
      " n_samples: 4\n",
      "   n_steps: 5\n",
      "        nu: 0.1\n",
      "radius_list: [0, 1]\n",
      "random_state: 42\n",
      "thickness_list: [1]\n",
      "\n",
      "Vectorizer:\n",
      "complexity: 4\n",
      "\n",
      "Estimator:\n",
      "     alpha: 1e-08\n",
      "      eta0: 0.01\n",
      "  l1_ratio: 0.698057935388\n",
      "learning_rate: optimal\n",
      "      loss: squared_hinge\n",
      "    n_iter: 89\n",
      "   penalty: elasticnet\n",
      "   power_t: 0.712351665998\n",
      "graph grammar stats:\n",
      "#instances:50   #interfaces: 50   #cores: 53   #core-interface-pairs: 158\n",
      "graph grammar stats:\n",
      "#instances:50   #interfaces: 64   #cores: 53   #core-interface-pairs: 199\n",
      "\n",
      "\n",
      "\tIteration: 2/5 (after 79.1 sec; 0:01:19.094457)\n",
      "Best score (roc_auc): 0.770 (0.859 +- 0.089)\n",
      "\n",
      "Data:\n",
      "Instances: 192 ; Features: 1048577 with an avg of 354 features\n",
      "class: 1 count:92 (0.48)\tclass: -1 count:100 (0.52)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "    burnin: 1\n",
      "complexity: 5\n",
      "improving_threshold: 0.5\n",
      "max_core_size_diff: 3\n",
      " n_samples: 4\n",
      "   n_steps: 5\n",
      "        nu: 0.33\n",
      "radius_list: [0, 1]\n",
      "random_state: 42\n",
      "thickness_list: [1, 2]\n",
      "\n",
      "Vectorizer:\n",
      "complexity: 4\n",
      "\n",
      "Estimator:\n",
      "     alpha: 1e-07\n",
      "      eta0: 0.01\n",
      "  l1_ratio: 0.698057935388\n",
      "learning_rate: invscaling\n",
      "      loss: squared_hinge\n",
      "    n_iter: 36\n",
      "   penalty: l2\n",
      "   power_t: 0.193562877926\n",
      "\n",
      "\n",
      "\tIteration: 2/5 (after 83.9 sec; 0:01:23.925014)\n",
      "Best score (roc_auc): 0.794 (0.882 +- 0.088)\n",
      "\n",
      "Data:\n",
      "Instances: 192 ; Features: 1048577 with an avg of 354 features\n",
      "class: 1 count:92 (0.48)\tclass: -1 count:100 (0.52)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "    burnin: 1\n",
      "complexity: 5\n",
      "improving_threshold: 0.5\n",
      "max_core_size_diff: 3\n",
      " n_samples: 4\n",
      "   n_steps: 5\n",
      "        nu: 0.33\n",
      "radius_list: [0, 1]\n",
      "random_state: 42\n",
      "thickness_list: [1, 2]\n",
      "\n",
      "Vectorizer:\n",
      "complexity: 4\n",
      "\n",
      "Estimator:\n",
      "     alpha: 1e-08\n",
      "      eta0: 0.01\n",
      "  l1_ratio: 0.698057935388\n",
      "learning_rate: optimal\n",
      "      loss: squared_hinge\n",
      "    n_iter: 89\n",
      "   penalty: elasticnet\n",
      "   power_t: 0.712351665998\n",
      "\n",
      "\n",
      "\tIteration: 2/5 (after 85.8 sec; 0:01:25.816994)\n",
      "Best score (roc_auc): 0.806 (0.881 +- 0.075)\n",
      "\n",
      "Data:\n",
      "Instances: 192 ; Features: 1048577 with an avg of 354 features\n",
      "class: 1 count:92 (0.48)\tclass: -1 count:100 (0.52)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "    burnin: 1\n",
      "complexity: 5\n",
      "improving_threshold: 0.5\n",
      "max_core_size_diff: 3\n",
      " n_samples: 4\n",
      "   n_steps: 5\n",
      "        nu: 0.33\n",
      "radius_list: [0, 1]\n",
      "random_state: 42\n",
      "thickness_list: [1, 2]\n",
      "\n",
      "Vectorizer:\n",
      "complexity: 4\n",
      "\n",
      "Estimator:\n",
      "     alpha: 1e-06\n",
      "      eta0: 0.01\n",
      "  l1_ratio: 0.698057935388\n",
      "learning_rate: constant\n",
      "      loss: squared_hinge\n",
      "    n_iter: 96\n",
      "   penalty: l2\n",
      "   power_t: 0.939838428481\n",
      "graph grammar stats:\n",
      "#instances:50   #interfaces: 50   #cores: 53   #core-interface-pairs: 158\n",
      "graph grammar stats:\n",
      "#instances:50   #interfaces: 64   #cores: 53   #core-interface-pairs: 199\n",
      "\n",
      "\n",
      "\tIteration: 3/5 (after 137.9 sec; 0:02:17.948988)\n",
      "Best score (roc_auc): 0.817 (0.915 +- 0.098)\n",
      "\n",
      "Data:\n",
      "Instances: 188 ; Features: 1048577 with an avg of 377 features\n",
      "class: 1 count:94 (0.50)\tclass: -1 count:94 (0.50)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "    burnin: 1\n",
      "complexity: 5\n",
      "improving_threshold: 0.25\n",
      "max_core_size_diff: 0\n",
      " n_samples: 4\n",
      "   n_steps: 5\n",
      "        nu: 0.1\n",
      "radius_list: [0, 1]\n",
      "random_state: 42\n",
      "thickness_list: [1, 2]\n",
      "\n",
      "Vectorizer:\n",
      "complexity: 4\n",
      "\n",
      "Estimator:\n",
      "     alpha: 1e-07\n",
      "      eta0: 0.01\n",
      "  l1_ratio: 0.698057935388\n",
      "learning_rate: optimal\n",
      "      loss: squared_hinge\n",
      "    n_iter: 89\n",
      "   penalty: elasticnet\n",
      "   power_t: 0.939838428481\n",
      "\n",
      "\n",
      "\tIteration: 3/5 (after 140.6 sec; 0:02:20.606755)\n",
      "Best score (roc_auc): 0.869 (0.929 +- 0.061)\n",
      "\n",
      "Data:\n",
      "Instances: 188 ; Features: 1048577 with an avg of 377 features\n",
      "class: 1 count:94 (0.50)\tclass: -1 count:94 (0.50)\t\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "    burnin: 1\n",
      "complexity: 5\n",
      "improving_threshold: 0.25\n",
      "max_core_size_diff: 0\n",
      " n_samples: 4\n",
      "   n_steps: 5\n",
      "        nu: 0.1\n",
      "radius_list: [0, 1]\n",
      "random_state: 42\n",
      "thickness_list: [1, 2]\n",
      "\n",
      "Vectorizer:\n",
      "complexity: 4\n",
      "\n",
      "Estimator:\n",
      "     alpha: 1e-07\n",
      "      eta0: 0.01\n",
      "  l1_ratio: 0.698057935388\n",
      "learning_rate: constant\n",
      "      loss: squared_hinge\n",
      "    n_iter: 89\n",
      "   penalty: l2\n",
      "   power_t: 0.193562877926\n",
      "graph grammar stats:\n",
      "#instances:50   #interfaces: 50   #cores: 53   #core-interface-pairs: 158\n",
      "graph grammar stats:\n",
      "#instances:50   #interfaces: 64   #cores: 53   #core-interface-pairs: 199\n",
      "graph grammar stats:\n",
      "#instances:50   #interfaces: 50   #cores: 53   #core-interface-pairs: 158\n",
      "graph grammar stats:\n",
      "#instances:50   #interfaces: 64   #cores: 53   #core-interface-pairs: 199\n",
      "Saved current best model in bursi\n",
      "Parameters:\n",
      "\n",
      "\tModel parameters:\n",
      "\n",
      "Pre_processor:\n",
      "    burnin: 1\n",
      "complexity: 5\n",
      "improving_threshold: 0.25\n",
      "max_core_size_diff: 0\n",
      " n_samples: 4\n",
      "   n_steps: 5\n",
      "        nu: 0.1\n",
      "radius_list: [0, 1]\n",
      "random_state: 42\n",
      "thickness_list: [1, 2]\n",
      "\n",
      "Vectorizer:\n",
      "complexity: 4\n",
      "\n",
      "Estimator:\n",
      "     alpha: 1e-07\n",
      "      eta0: 0.01\n",
      "  l1_ratio: 0.698057935388\n",
      "learning_rate: constant\n",
      "      loss: squared_hinge\n",
      "    n_iter: 89\n",
      "   penalty: l2\n",
      "   power_t: 0.193562877926\n",
      "Test set\n",
      "Instances: 100 ; Features: 1048577 with an avg of 334 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.71      0.70      0.71        50\n",
      "          1       0.71      0.72      0.71        50\n",
      "\n",
      "avg / total       0.71      0.71      0.71       100\n",
      "\n",
      "APR: 0.773\n",
      "ROC: 0.802\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.670 +- 0.144\n",
      "           precision: 0.677 +- 0.165\n",
      "              recall: 0.700 +- 0.126\n",
      "                  f1: 0.683 +- 0.137\n",
      "   average_precision: 0.797 +- 0.104\n",
      "             roc_auc: 0.780 +- 0.110\n",
      "CPU times: user 28.2 s, sys: 8.75 s, total: 37 s\n",
      "Wall time: 4min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pos_fname='bursi_pos_orig.smi'\n",
    "neg_fname='bursi_neg_orig.smi'\n",
    "model = constructive_model(pos_fname, neg_fname, size=100, model_fname='bursi', n_iter=5, train_test_split=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Params:\n",
      "    burnin: 1\n",
      "complexity: 5\n",
      "improving_threshold: 0.25\n",
      "max_core_size_diff: 0\n",
      " n_samples: 4\n",
      "   n_steps: 5\n",
      "        nu: 0.1\n",
      "radius_list: [0, 1]\n",
      "random_state: 42\n",
      "thickness_list: [1, 2]\n",
      "--------------------------------------------------------------------------------\n",
      "Grammar induction:\n",
      "Positives:\n",
      "graph grammar stats:\n",
      "#instances:70   #interfaces: 72   #cores: 75   #core-interface-pairs: 241\n",
      "Time elapsed: 0:00:05.828723\n",
      "Negatives:\n",
      "graph grammar stats:\n",
      "#instances:70   #interfaces: 86   #cores: 63   #core-interface-pairs: 262\n",
      "Time elapsed: 0:00:05.877782\n",
      "--------------------------------------------------------------------------------\n",
      "Fitting:\n",
      "Time elapsed: 0:01:04.146812\n",
      "--------------------------------------------------------------------------------\n",
      "Testing:\n",
      "Test set\n",
      "Instances: 60 ; Features: 1048577 with an avg of 463 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.68      0.50      0.58        30\n",
      "          1       0.61      0.77      0.68        30\n",
      "\n",
      "avg / total       0.64      0.63      0.63        60\n",
      "\n",
      "APR: 0.617\n",
      "ROC: 0.717\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.633 +- 0.113\n",
      "           precision: 0.610 +- 0.091\n",
      "              recall: 0.767 +- 0.170\n",
      "                  f1: 0.672 +- 0.107\n",
      "   average_precision: 0.731 +- 0.157\n",
      "             roc_auc: 0.733 +- 0.144\n",
      "Time elapsed: 0:00:02.400114\n",
      "Global time elapsed: 0:01:18.427208\n",
      "CPU times: user 8.3 s, sys: 3.01 s, total: 11.3 s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#explicit experiment\n",
    "start_global = time()\n",
    "\n",
    "#train a model on data, then test it on original data (different from the mols that generated the data) and compare \n",
    "from eden.graph import Vectorizer\n",
    "vectorizer=Vectorizer(5)\n",
    "\n",
    "#setup\n",
    "size=100\n",
    "pos_fname='bursi_pos_orig.smi'\n",
    "neg_fname='bursi_neg_orig.smi'\n",
    "iterable_pos= get_graphs(pos_fname, size=size)\n",
    "iterable_neg= get_graphs(neg_fname, size=size)\n",
    "random_state=42\n",
    "train_test_split=.7\n",
    "\n",
    "#split train/test\n",
    "from eden.util import random_bipartition_iter\n",
    "iterable_pos_train, iterable_pos_test = random_bipartition_iter(iterable_pos, relative_size=train_test_split)\n",
    "iterable_neg_train, iterable_neg_test = random_bipartition_iter(iterable_neg, relative_size=train_test_split)\n",
    "\n",
    "args = {'random_state':42,\n",
    "        'complexity':5,\n",
    "        'nu':0.1,\n",
    "        'radius_list':[0,1],\n",
    "        'thickness_list':[1,2],\n",
    "        'n_steps':5,\n",
    "        'n_samples':4,\n",
    "        'burnin':1,\n",
    "        'improving_threshold':0.25,\n",
    "        'max_core_size_diff':0}\n",
    "            \n",
    "logger.info('-'*80)\n",
    "logger.info('Params:')\n",
    "from eden.util import serialize_dict\n",
    "logger.info(serialize_dict(args))\n",
    "\n",
    "#train\n",
    "start = time()\n",
    "logger.info('-'*80)\n",
    "logger.info('Grammar induction:')\n",
    "logger.info('Positives:')\n",
    "sampled_pos = generate_sample(iterable_pos_train, **args)\n",
    "logger.info('Time elapsed: %s'%(datetime.timedelta(seconds=(time() - start))))\n",
    "\n",
    "start = time()\n",
    "logger.info('Negatives:')\n",
    "sampled_neg = generate_sample(iterable_neg_train, **args)\n",
    "print('Time elapsed: %s'%(datetime.timedelta(seconds=(time() - start))))\n",
    "\n",
    "start = time()\n",
    "logger.info('-'*80)\n",
    "logger.info('Fitting:')\n",
    "from eden.util import fit\n",
    "estimator = fit(sampled_pos, \n",
    "                sampled_neg, \n",
    "                vectorizer, \n",
    "                fit_flag=False, \n",
    "                n_jobs=-1, \n",
    "                cv=10, \n",
    "                n_iter_search=5, \n",
    "                random_state=1, \n",
    "                block_size=100)\n",
    "logger.info('Time elapsed: %s'%(datetime.timedelta(seconds=(time() - start))))\n",
    "\n",
    "\n",
    "#test\n",
    "start = time()\n",
    "logger.info('-'*80)\n",
    "logger.info('Testing:')\n",
    "from eden.util import estimate\n",
    "apr, roc = estimate(iterable_pos_test,\n",
    "                    iterable_neg_test,  \n",
    "                    estimator, \n",
    "                    vectorizer, \n",
    "                    block_size=100, \n",
    "                    n_jobs=-1)\n",
    "logger.info('Time elapsed: %s'%(datetime.timedelta(seconds=(time() - start))))\n",
    "\n",
    "logger.info('Global time elapsed: %s'%(datetime.timedelta(seconds=(time() - start_global))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
