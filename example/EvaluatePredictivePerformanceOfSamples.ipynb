{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import eden\n",
    "import matplotlib.pyplot as plt\n",
    "from eden.util import configure_logging\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import tee, chain, islice\n",
    "import numpy as np\n",
    "import random\n",
    "from time import time\n",
    "import datetime\n",
    "from graphlearn.graphlearn import GraphLearnSampler\n",
    "from eden.util import fit,estimate\n",
    "from eden.graph import Vectorizer\n",
    "# get data\n",
    "from eden.converter.graph.gspan import gspan_to_eden\n",
    "from itertools import islice\n",
    "def get_graphs(dataset_fname, size=100):\n",
    "    return  islice(gspan_to_eden(dataset_fname),size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_sample(graphs, random_state=42):\n",
    "    graphs, graphs_ = tee(graphs)\n",
    "    sampler=GraphLearnSampler(radius_list=[0,1],thickness_list=[2],\n",
    "                              min_cip_count=2, min_interface_count=2,\n",
    "                              vectorizer=Vectorizer(5), random_state=random_state)\n",
    "    \n",
    "    sampler.fit(graphs, nu=0.25, n_jobs=-1)\n",
    "\n",
    "    logger.info('graph grammar stats:')\n",
    "    dataset_size, interface_counts, core_counts, cip_counts = sampler.grammar().size()\n",
    "    logger.info('#instances:%d   #interfaces: %d   #cores: %d   #core-interface-pairs: %d' % (dataset_size, interface_counts, core_counts, cip_counts))\n",
    "    graphs = sampler.sample(graphs_,\n",
    "                            n_steps=5, n_samples=4,\n",
    "                            target_orig_cip=False,\n",
    "                            probabilistic_core_choice=False,\n",
    "                            score_core_choice= False,\n",
    "                            max_core_size_diff=3,\n",
    "                            burnin=1,\n",
    "                            omit_seed=True,\n",
    "                            max_cycle_size=6,\n",
    "                            improving_threshold=0.25,\n",
    "                            accept_static_penalty=0,\n",
    "                            n_jobs=-1,\n",
    "                            select_cip_max_tries=200,\n",
    "                            keep_duplicates=True,\n",
    "                            generator_mode=True)\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_and_evaluate(pos_original, neg_original,\n",
    "                     pos_sampled, neg_sampled,\n",
    "                     pos_test, neg_test,\n",
    "                     random_state=42):\n",
    "    # create graph sets...orig augmented and sampled\n",
    "    pos_orig,pos_orig_ = tee(pos_original)\n",
    "    neg_orig,neg_orig_ = tee(neg_original)\n",
    "    \n",
    "    pos_sampled, pos_sampled_ = tee(pos_sampled)\n",
    "    neg_sampled, neg_sampled_ = tee(neg_sampled)\n",
    "    \n",
    "    pos_augmented = chain(pos_orig_,pos_sampled_)\n",
    "    neg_augmented = chain(neg_orig_,neg_sampled_)\n",
    "\n",
    "    predictive_performances = []\n",
    "    for desc,pos_train,neg_train in [('original',pos_orig, neg_orig),\n",
    "                                     ('sample',pos_sampled,neg_sampled),\n",
    "                                     ('original+sample',pos_augmented, neg_augmented)]:\n",
    "        pos_train,pos_train_ = tee(pos_train)\n",
    "        neg_train,neg_train_ = tee(neg_train)\n",
    "        pos_size=sum(1 for x in pos_train_)\n",
    "        neg_size=sum(1 for x in neg_train_)\n",
    "\n",
    "        logger.info( \"-\"*80)\n",
    "        logger.info('working on %s'%(desc))\n",
    "        logger.info('training set sizes: #pos: %d #neg: %d'%(pos_size, neg_size))\n",
    "\n",
    "        if pos_size == 0 or neg_size == 0:\n",
    "            logger.info('WARNING: empty dataset')\n",
    "            predictive_performances.append(0)            \n",
    "        else:\n",
    "            start=time()\n",
    "            pos_test,pos_test_ = tee(pos_test)\n",
    "            neg_test,neg_test_ = tee(neg_test)\n",
    "            local_estimator = fit(pos_train, neg_train, Vectorizer(4), n_jobs=-1, n_iter_search=1)\n",
    "            apr, roc = estimate(pos_test_, neg_test_, local_estimator, Vectorizer(4))\n",
    "            predictive_performances.append(roc)\n",
    "            logger.info( 'elapsed: %.1f sec'%(time()-start))\n",
    "    return predictive_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(pos_fname, neg_fname, size=None, percentages=None, n_repetitions=None, train_test_split=None):\n",
    "    # initializing \n",
    "    graphs_pos = get_graphs(pos_fname, size=size)\n",
    "    graphs_neg = get_graphs(neg_fname, size=size)\n",
    "\n",
    "    # train/test split\n",
    "    from eden.util import random_bipartition_iter\n",
    "    pos_train_global,pos_test_global = random_bipartition_iter(graphs_pos,train_test_split)\n",
    "    neg_train_global,neg_test_global = random_bipartition_iter(graphs_neg,train_test_split)\n",
    "\n",
    "\n",
    "    original_repetitions = []\n",
    "    original_sample_repetitions = []\n",
    "    sample_repetitions = []\n",
    "\n",
    "    for percentage in percentages:\n",
    "        originals = []\n",
    "        originals_samples = []\n",
    "        samples = []\n",
    "        for repetition in range(n_repetitions):\n",
    "            random_state = int(313379*percentage+repetition) \n",
    "            random.seed(random_state)\n",
    "            pos_train_global,pos_train_global_ = tee(pos_train_global)\n",
    "            neg_train_global,neg_train_global_ = tee(neg_train_global)\n",
    "            pos_test_global,pos_test_global_ = tee(pos_test_global)\n",
    "            neg_test_global,neg_test_global_ = tee(neg_test_global)\n",
    "\n",
    "            # use shuffled list to create test and sample set\n",
    "            pos,pos_reminder = random_bipartition_iter(pos_train_global_,percentage)\n",
    "            pos,pos_ = tee(pos)\n",
    "            neg,neg_reminder = random_bipartition_iter(neg_train_global_,percentage)\n",
    "            neg,neg_ = tee(neg)\n",
    "\n",
    "            #sample independently from the 2 classes\n",
    "            logger.info('Positive')\n",
    "            sampled_pos = fit_sample(pos_, random_state=random_state)\n",
    "            logger.info('Negative')\n",
    "            sampled_neg = fit_sample(neg_, random_state=random_state)\n",
    "\n",
    "            #evaluate the predictive performance on held out test set\n",
    "            start=time()\n",
    "            logger.info( \"=\"*80)\n",
    "            logger.info( 'repetition: %d/%d'%(repetition+1, n_repetitions))\n",
    "            logger.info( \"training percentage:\"+str(percentage))\n",
    "            perf_orig,\\\n",
    "            perf_samp,\\\n",
    "            perf_orig_samp = fit_and_evaluate(pos,neg,\n",
    "                                              sampled_pos,sampled_neg,\n",
    "                                              pos_test_global_,neg_test_global_)\n",
    "            logger.info( 'Time elapsed: %.1f sec'%((time()-start)))\n",
    "            originals.append(perf_orig)\n",
    "            originals_samples.append(perf_orig_samp)\n",
    "            samples.append(perf_samp)\n",
    "\n",
    "        original_repetitions.append(originals)\n",
    "        original_sample_repetitions.append(originals_samples)\n",
    "        sample_repetitions.append(samples)\n",
    "    \n",
    "    return original_repetitions, original_sample_repetitions, sample_repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot(dataset, percentages, original_sample_repetitions, original_repetitions, sample_repetitions):\n",
    "    gc={'color':'g'}\n",
    "    rc={'color':'r'}\n",
    "    bc={'color':'b'}\n",
    "    ws = 0.02\n",
    "    os = np.mean(original_sample_repetitions, axis=1)\n",
    "    o = np.mean(original_repetitions, axis=1)\n",
    "    s = np.mean(sample_repetitions, axis=1)\n",
    "    plt.figure(figsize=(18,8))\n",
    "    plt.grid()\n",
    "    plt.boxplot(original_sample_repetitions, positions=percentages, widths=ws, capprops=gc, medianprops=gc, boxprops=gc, whiskerprops=gc, flierprops=gc)\n",
    "    plt.plot(percentages,os, color='g', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='g', markerfacecolor='w', label='original+sample')\n",
    "\n",
    "    plt.boxplot(original_repetitions, positions=percentages, widths=ws, capprops=rc, medianprops=rc, boxprops=rc, whiskerprops=rc, flierprops=rc)\n",
    "    plt.plot(percentages,o, color='r', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='r', markerfacecolor='w', label='original')\n",
    "\n",
    "    plt.boxplot(sample_repetitions, positions=percentages, widths=ws, capprops=bc, medianprops=bc, boxprops=bc, whiskerprops=bc, flierprops=bc)\n",
    "    plt.plot(percentages,s, color='b', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='b', markerfacecolor='w', label='sample')\n",
    "\n",
    "    plt.xlim(percentages[0]-.05,percentages[-1]+.05)\n",
    "    plt.title(dataset+'\\n',fontsize=17)\n",
    "    plt.legend(loc='lower right',fontsize=16)\n",
    "    plt.ylabel('ROC AUC',fontsize=16)\n",
    "    plt.xlabel('Dataset size (fraction)',fontsize=16)\n",
    "    plt.savefig('%s_plot_predictive_performance_of_samples.pdf' % dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions):\n",
    "    with open(result_fname,'w') as f:\n",
    "        f.write('dataset sizes list:\\n')\n",
    "        for perc in percentages:\n",
    "            f.write('%s '% perc)\n",
    "        f.write('\\n')\n",
    "        f.write('AUC scores:\\n')\n",
    "        for repetitions in original_repetitions,original_sample_repetitions,sample_repetitions:\n",
    "            f.write('%s\\n' % len(repetitions))\n",
    "            for repetition in repetitions:\n",
    "                for auc in repetition:\n",
    "                    f.write('%s ' % auc)\n",
    "                f.write('\\n')\n",
    "    \n",
    "def load_results(result_fname):\n",
    "    with open(result_fname) as f:\n",
    "        comment = next(f)\n",
    "        line = next(f)\n",
    "        percentages = [float(x) for x in line.split()]\n",
    "        comment = next(f)\n",
    "\n",
    "        original_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            original_repetitions.append(repetition)\n",
    "\n",
    "        original_sample_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            original_sample_repetitions.append(repetition)\n",
    "\n",
    "\n",
    "        sample_repetitions = []\n",
    "        size = int(next(f))\n",
    "        for i in range(size):\n",
    "            line = next(f)\n",
    "            repetition = [float(x) for x in line.split()]\n",
    "            sample_repetitions.append(repetition)\n",
    "            \n",
    "    return percentages, original_repetitions,original_sample_repetitions,sample_repetitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Experimental pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setup\n",
    "dataset_names = !cat NCI60/names\n",
    "random.shuffle(dataset_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with dataset: SF_268_t\n",
      "Working with dataset: SF_268_t\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#instances:14   #interfaces: 9   #cores: 5   #core-interface-pairs: 18\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#instances:14   #interfaces: 5   #cores: 10   #core-interface-pairs: 11\n",
      "================================================================================\n",
      "repetition: 1/3\n",
      "training percentage:0.05\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 14 #neg: 14\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.61      0.44      0.51       120\n",
      "          1       0.56      0.72      0.63       120\n",
      "\n",
      "avg / total       0.59      0.58      0.57       240\n",
      "\n",
      "APR: 0.614\n",
      "ROC: 0.628\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.679 +- 0.047\n",
      "           precision: 0.685 +- 0.016\n",
      "              recall: 0.658 +- 0.145\n",
      "                  f1: 0.664 +- 0.087\n",
      "   average_precision: 0.720 +- 0.055\n",
      "             roc_auc: 0.747 +- 0.062\n",
      "elapsed: 4.2 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 26 #neg: 22\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.54      0.42      0.48       120\n",
      "          1       0.53      0.64      0.58       120\n",
      "\n",
      "avg / total       0.53      0.53      0.53       240\n",
      "\n",
      "APR: 0.593\n",
      "ROC: 0.564\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.679 +- 0.045\n",
      "           precision: 0.684 +- 0.042\n",
      "              recall: 0.667 +- 0.102\n",
      "                  f1: 0.672 +- 0.061\n",
      "   average_precision: 0.724 +- 0.045\n",
      "             roc_auc: 0.749 +- 0.044\n",
      "elapsed: 4.3 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 40 #neg: 36\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.58      0.63      0.60       120\n",
      "          1       0.59      0.53      0.56       120\n",
      "\n",
      "avg / total       0.58      0.58      0.58       240\n",
      "\n",
      "APR: 0.622\n",
      "ROC: 0.641\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.679 +- 0.047\n",
      "           precision: 0.687 +- 0.056\n",
      "              recall: 0.675 +- 0.119\n",
      "                  f1: 0.673 +- 0.064\n",
      "   average_precision: 0.713 +- 0.057\n",
      "             roc_auc: 0.729 +- 0.061\n",
      "elapsed: 4.6 sec\n",
      "Time elapsed: 19.4 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#instances:14   #interfaces: 9   #cores: 5   #core-interface-pairs: 18\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#instances:14   #interfaces: 5   #cores: 10   #core-interface-pairs: 11\n",
      "================================================================================\n",
      "repetition: 2/3\n",
      "training percentage:0.05\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 14 #neg: 14\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.64      0.49      0.56       120\n",
      "          1       0.59      0.72      0.65       120\n",
      "\n",
      "avg / total       0.61      0.61      0.60       240\n",
      "\n",
      "APR: 0.631\n",
      "ROC: 0.655\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.671 +- 0.055\n",
      "           precision: 0.681 +- 0.045\n",
      "              recall: 0.633 +- 0.113\n",
      "                  f1: 0.653 +- 0.078\n",
      "   average_precision: 0.706 +- 0.064\n",
      "             roc_auc: 0.734 +- 0.047\n",
      "elapsed: 4.1 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 26 #neg: 22\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.55      0.66      0.60       120\n",
      "          1       0.58      0.47      0.52       120\n",
      "\n",
      "avg / total       0.56      0.56      0.56       240\n",
      "\n",
      "APR: 0.559\n",
      "ROC: 0.547\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.654 +- 0.031\n",
      "           precision: 0.664 +- 0.006\n",
      "              recall: 0.625 +- 0.124\n",
      "                  f1: 0.637 +- 0.071\n",
      "   average_precision: 0.714 +- 0.045\n",
      "             roc_auc: 0.744 +- 0.052\n",
      "elapsed: 4.5 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 40 #neg: 36\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.57      0.61      0.59       120\n",
      "          1       0.58      0.54      0.56       120\n",
      "\n",
      "avg / total       0.58      0.57      0.57       240\n",
      "\n",
      "APR: 0.617\n",
      "ROC: 0.613\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.667 +- 0.044\n",
      "           precision: 0.680 +- 0.052\n",
      "              recall: 0.642 +- 0.128\n",
      "                  f1: 0.652 +- 0.069\n",
      "   average_precision: 0.706 +- 0.022\n",
      "             roc_auc: 0.723 +- 0.053\n",
      "elapsed: 4.6 sec\n",
      "Time elapsed: 19.3 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#instances:14   #interfaces: 9   #cores: 5   #core-interface-pairs: 18\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#instances:14   #interfaces: 5   #cores: 10   #core-interface-pairs: 11\n",
      "================================================================================\n",
      "repetition: 3/3\n",
      "training percentage:0.05\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 14 #neg: 14\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.62      0.66      0.64       120\n",
      "          1       0.63      0.59      0.61       120\n",
      "\n",
      "avg / total       0.63      0.62      0.62       240\n",
      "\n",
      "APR: 0.605\n",
      "ROC: 0.662\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.675 +- 0.041\n",
      "           precision: 0.681 +- 0.027\n",
      "              recall: 0.658 +- 0.127\n",
      "                  f1: 0.663 +- 0.072\n",
      "   average_precision: 0.715 +- 0.050\n",
      "             roc_auc: 0.735 +- 0.057\n",
      "elapsed: 4.2 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 26 #neg: 22\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.53      0.47      0.50       120\n",
      "          1       0.53      0.58      0.55       120\n",
      "\n",
      "avg / total       0.53      0.53      0.53       240\n",
      "\n",
      "APR: 0.590\n",
      "ROC: 0.559\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.671 +- 0.055\n",
      "           precision: 0.665 +- 0.037\n",
      "              recall: 0.683 +- 0.155\n",
      "                  f1: 0.666 +- 0.092\n",
      "   average_precision: 0.723 +- 0.048\n",
      "             roc_auc: 0.744 +- 0.047\n",
      "elapsed: 4.5 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 40 #neg: 36\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.59      0.61      0.60       120\n",
      "          1       0.59      0.57      0.58       120\n",
      "\n",
      "avg / total       0.59      0.59      0.59       240\n",
      "\n",
      "APR: 0.616\n",
      "ROC: 0.637\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.683 +- 0.040\n",
      "           precision: 0.697 +- 0.037\n",
      "              recall: 0.650 +- 0.101\n",
      "                  f1: 0.669 +- 0.060\n",
      "   average_precision: 0.726 +- 0.040\n",
      "             roc_auc: 0.754 +- 0.043\n",
      "elapsed: 4.5 sec\n",
      "Time elapsed: 19.8 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#instances:56   #interfaces: 37   #cores: 27   #core-interface-pairs: 94\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#instances:56   #interfaces: 34   #cores: 28   #core-interface-pairs: 86\n",
      "================================================================================\n",
      "repetition: 1/3\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 56 #neg: 56\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.68      0.56      0.61       120\n",
      "          1       0.62      0.73      0.67       120\n",
      "\n",
      "avg / total       0.65      0.65      0.64       240\n",
      "\n",
      "APR: 0.621\n",
      "ROC: 0.671\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.671 +- 0.083\n",
      "           precision: 0.667 +- 0.082\n",
      "              recall: 0.667 +- 0.142\n",
      "                  f1: 0.664 +- 0.107\n",
      "   average_precision: 0.709 +- 0.052\n",
      "             roc_auc: 0.733 +- 0.065\n",
      "elapsed: 5.1 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 110 #neg: 110\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.66      0.62      0.64       120\n",
      "          1       0.64      0.68      0.66       120\n",
      "\n",
      "avg / total       0.65      0.65      0.65       240\n",
      "\n",
      "APR: 0.627\n",
      "ROC: 0.685\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.683 +- 0.046\n",
      "           precision: 0.678 +- 0.024\n",
      "              recall: 0.692 +- 0.136\n",
      "                  f1: 0.679 +- 0.079\n",
      "   average_precision: 0.701 +- 0.051\n",
      "             roc_auc: 0.728 +- 0.066\n",
      "elapsed: 5.7 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 166 #neg: 166\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.69      0.60      0.64       120\n",
      "          1       0.64      0.72      0.68       120\n",
      "\n",
      "avg / total       0.67      0.66      0.66       240\n",
      "\n",
      "APR: 0.674\n",
      "ROC: 0.703\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.692 +- 0.031\n",
      "           precision: 0.698 +- 0.035\n",
      "              recall: 0.683 +- 0.086\n",
      "                  f1: 0.687 +- 0.045\n",
      "   average_precision: 0.714 +- 0.046\n",
      "             roc_auc: 0.737 +- 0.041\n",
      "elapsed: 6.8 sec\n",
      "Time elapsed: 27.3 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#instances:56   #interfaces: 37   #cores: 27   #core-interface-pairs: 94\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#instances:56   #interfaces: 34   #cores: 28   #core-interface-pairs: 86\n",
      "================================================================================\n",
      "repetition: 2/3\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 56 #neg: 56\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.66      0.62      0.64       120\n",
      "          1       0.65      0.68      0.66       120\n",
      "\n",
      "avg / total       0.65      0.65      0.65       240\n",
      "\n",
      "APR: 0.642\n",
      "ROC: 0.690\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.683 +- 0.044\n",
      "           precision: 0.679 +- 0.027\n",
      "              recall: 0.692 +- 0.128\n",
      "                  f1: 0.680 +- 0.073\n",
      "   average_precision: 0.705 +- 0.061\n",
      "             roc_auc: 0.735 +- 0.061\n",
      "elapsed: 5.0 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 110 #neg: 109\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.66      0.64      0.65       120\n",
      "          1       0.65      0.68      0.66       120\n",
      "\n",
      "avg / total       0.66      0.66      0.66       240\n",
      "\n",
      "APR: 0.616\n",
      "ROC: 0.690\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.671 +- 0.050\n",
      "           precision: 0.673 +- 0.040\n",
      "              recall: 0.667 +- 0.126\n",
      "                  f1: 0.664 +- 0.072\n",
      "   average_precision: 0.707 +- 0.030\n",
      "             roc_auc: 0.726 +- 0.055\n",
      "elapsed: 5.7 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 166 #neg: 165\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.68      0.63      0.66       120\n",
      "          1       0.66      0.71      0.68       120\n",
      "\n",
      "avg / total       0.67      0.67      0.67       240\n",
      "\n",
      "APR: 0.655\n",
      "ROC: 0.717\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.671 +- 0.044\n",
      "           precision: 0.682 +- 0.023\n",
      "              recall: 0.633 +- 0.113\n",
      "                  f1: 0.653 +- 0.072\n",
      "   average_precision: 0.696 +- 0.051\n",
      "             roc_auc: 0.733 +- 0.058\n",
      "elapsed: 6.7 sec\n",
      "Time elapsed: 26.7 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#instances:56   #interfaces: 37   #cores: 27   #core-interface-pairs: 94\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#instances:56   #interfaces: 34   #cores: 28   #core-interface-pairs: 86\n",
      "================================================================================\n",
      "repetition: 3/3\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 56 #neg: 56\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.66      0.62      0.64       120\n",
      "          1       0.64      0.68      0.66       120\n",
      "\n",
      "avg / total       0.65      0.65      0.65       240\n",
      "\n",
      "APR: 0.644\n",
      "ROC: 0.690\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.667 +- 0.044\n",
      "           precision: 0.671 +- 0.035\n",
      "              recall: 0.658 +- 0.125\n",
      "                  f1: 0.658 +- 0.071\n",
      "   average_precision: 0.721 +- 0.058\n",
      "             roc_auc: 0.742 +- 0.066\n",
      "elapsed: 5.1 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 110 #neg: 110\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.61      0.60      0.61       120\n",
      "          1       0.61      0.62      0.61       120\n",
      "\n",
      "avg / total       0.61      0.61      0.61       240\n",
      "\n",
      "APR: 0.581\n",
      "ROC: 0.639\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.679 +- 0.047\n",
      "           precision: 0.684 +- 0.050\n",
      "              recall: 0.675 +- 0.116\n",
      "                  f1: 0.674 +- 0.063\n",
      "   average_precision: 0.737 +- 0.060\n",
      "             roc_auc: 0.758 +- 0.055\n",
      "elapsed: 6.2 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 166 #neg: 166\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.68      0.61      0.64       120\n",
      "          1       0.64      0.71      0.67       120\n",
      "\n",
      "avg / total       0.66      0.66      0.66       240\n",
      "\n",
      "APR: 0.642\n",
      "ROC: 0.692\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.692 +- 0.052\n",
      "           precision: 0.690 +- 0.037\n",
      "              recall: 0.692 +- 0.122\n",
      "                  f1: 0.687 +- 0.073\n",
      "   average_precision: 0.706 +- 0.053\n",
      "             roc_auc: 0.735 +- 0.062\n",
      "elapsed: 6.6 sec\n",
      "Time elapsed: 27.5 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#instances:112   #interfaces: 88   #cores: 41   #core-interface-pairs: 245\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#instances:112   #interfaces: 68   #cores: 39   #core-interface-pairs: 183\n",
      "================================================================================\n",
      "repetition: 1/3\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 112 #neg: 112\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.69      0.68      0.68       120\n",
      "          1       0.68      0.70      0.69       120\n",
      "\n",
      "avg / total       0.69      0.69      0.69       240\n",
      "\n",
      "APR: 0.730\n",
      "ROC: 0.739\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.633 +- 0.061\n",
      "           precision: 0.636 +- 0.056\n",
      "              recall: 0.608 +- 0.131\n",
      "                  f1: 0.618 +- 0.089\n",
      "   average_precision: 0.702 +- 0.056\n",
      "             roc_auc: 0.725 +- 0.069\n",
      "elapsed: 5.7 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 218 #neg: 220\n",
      "Test set\n",
      "Instances: 240 ; Features: 1048577 with an avg of 416 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.69      0.68      0.69       120\n",
      "          1       0.69      0.69      0.69       120\n",
      "\n",
      "avg / total       0.69      0.69      0.69       240\n",
      "\n",
      "APR: 0.694\n",
      "ROC: 0.721\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.688 +- 0.035\n",
      "           precision: 0.701 +- 0.024\n",
      "              recall: 0.658 +- 0.110\n",
      "                  f1: 0.674 +- 0.058\n",
      "   average_precision: 0.719 +- 0.060\n",
      "             roc_auc: 0.733 +- 0.052\n",
      "elapsed: 7.4 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 330 #neg: 332\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "for dataset in dataset_names:\n",
    "    #logging\n",
    "    logger = logging.getLogger()\n",
    "    if True:\n",
    "        logger_fname = '%s_predictive_performance_of_samples.log'%dataset\n",
    "    else:\n",
    "        logger_fname = None\n",
    "    configure_logging(logger,verbosity=1, filename=logger_fname)\n",
    "    \n",
    "    #main \n",
    "    start=time()\n",
    "    print( 'Working with dataset: %s' % dataset )\n",
    "\n",
    "    logger.info( 'Working with dataset: %s' % dataset )\n",
    "    pos_dataset_fname = 'NCI60/' + dataset + '_orig_pos.gspan'\n",
    "    neg_dataset_fname = 'NCI60/' + dataset + '_orig_neg.gspan'\n",
    "    #pos_dataset_fname = 'bursi.pos.gspan'\n",
    "    #neg_dataset_fname = 'bursi.neg.gspan'\n",
    "\n",
    "    percentages=[.05,.2,.4,.6,.8,.95]\n",
    "\n",
    "    original_repetitions,\\\n",
    "    original_sample_repetitions,\\\n",
    "    sample_repetitions = evaluate(pos_dataset_fname,\n",
    "                                  neg_dataset_fname,\n",
    "                                  size=400,\n",
    "                                  percentages=percentages,\n",
    "                                  n_repetitions=3,\n",
    "                                  train_test_split=0.7)\n",
    "    #save and display results\n",
    "    result_fname='%s_predictive_performance_of_samples.data'%dataset\n",
    "    save_results(result_fname,percentages, original_repetitions,original_sample_repetitions,sample_repetitions)    \n",
    "    percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results(result_fname)\n",
    "    plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\n",
    "    \n",
    "    print('Time elapsed: %s'%(datetime.timedelta(seconds=(time() - start))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#display\n",
    "for dataset in dataset_names:\n",
    "    result_fname='%s_predictive_performance_of_samples.data'%dataset\n",
    "    percentages_l, original_repetitions_l,original_sample_repetitions_l,sample_repetitions_l = load_results(result_fname)\n",
    "    plot(dataset, percentages_l, original_sample_repetitions_l, original_repetitions_l, sample_repetitions_l)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
