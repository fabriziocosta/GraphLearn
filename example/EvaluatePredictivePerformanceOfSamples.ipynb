{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from eden.util import configure_logging\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import tee, chain, islice\n",
    "import numpy as np\n",
    "import random\n",
    "from time import time\n",
    "from graphlearn.graphlearn import GraphLearnSampler\n",
    "from eden.util import fit,estimate\n",
    "from eden.graph import Vectorizer\n",
    "# get data\n",
    "from eden.converter.graph.gspan import gspan_to_eden\n",
    "from itertools import islice\n",
    "def get_graphs(dataset_fname, size=100):\n",
    "    return  islice(gspan_to_eden(dataset_fname),size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_sample(graphs):\n",
    "    graphs, graphs_ = tee(graphs)\n",
    "    sampler=GraphLearnSampler(radius_list=[0,1],thickness_list=[1],\n",
    "                              min_cip_count=2, min_interface_count=2,\n",
    "                              vectorizer=Vectorizer(5))\n",
    "    \n",
    "    sampler.fit(graphs, nu=0.5, n_jobs=-1)\n",
    "\n",
    "    print('graph grammar stats:')\n",
    "    interface_counts, core_counts, cip_counts = sampler.grammar().size()\n",
    "    print('#interfaces: %d   #cores: %d   #core-interface-pairs: %d' % (interface_counts, core_counts, cip_counts))\n",
    "    graphs = sampler.sample(graphs_,\n",
    "                            n_steps=5, n_samples=4,\n",
    "                            target_orig_cip=True,\n",
    "                            probabilistic_core_choice=False,\n",
    "                            score_core_choice= True,\n",
    "                            max_core_size_diff=0,\n",
    "                            improving_threshold=0.5, accept_static_penalty=0,\n",
    "                            generator_mode=True,\n",
    "                            n_jobs=-1,burnin=1,select_cip_max_tries=200,keep_duplicates=True)\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_and_evaluate(pos_original, neg_original,\n",
    "                     pos_sampled, neg_sampled,\n",
    "                     pos_test, neg_test):\n",
    "    # create graph sets...orig augmented and sampled\n",
    "    pos_orig,pos_orig_ = tee(pos_original)\n",
    "    neg_orig,neg_orig_ = tee(neg_original)\n",
    "    \n",
    "    pos_sampled, pos_sampled_ = tee(pos_sampled)\n",
    "    neg_sampled, neg_sampled_ = tee(neg_sampled)\n",
    "    \n",
    "    pos_augmented = chain(pos_orig_,pos_sampled_)\n",
    "    neg_augmented = chain(neg_orig_,neg_sampled_)\n",
    "\n",
    "    predictive_performances = []\n",
    "    for desc,pos_train,neg_train in [('original',pos_orig, neg_orig),\n",
    "                                     ('sample',pos_sampled,neg_sampled),\n",
    "                                     ('original+sample',pos_augmented, neg_augmented)]:\n",
    "        pos_train,pos_train_ = tee(pos_train)\n",
    "        neg_train,neg_train_ = tee(neg_train)\n",
    "        pos_size=sum(1 for x in pos_train_)\n",
    "        neg_size=sum(1 for x in neg_train_)\n",
    "        if pos_size == 0 or neg_size == 0:\n",
    "            print \"-\"*80\n",
    "            print 'working on %s'%(desc)\n",
    "            print 'training set sizes: #pos: %d #neg: %d'%(pos_size, neg_size)\n",
    "            print 'WARNING: empty dataset'\n",
    "            predictive_performances.append(0)            \n",
    "        else:\n",
    "            start=time()\n",
    "            print \"-\"*80\n",
    "            print 'working on %s'%(desc)\n",
    "            print 'training set sizes: #pos: %d #neg: %d'%(pos_size, neg_size)\n",
    "            pos_test,pos_test_ = tee(pos_test)\n",
    "            neg_test,neg_test_ = tee(neg_test)\n",
    "            local_estimator = fit(pos_train, neg_train, Vectorizer(4), n_jobs=-1, n_iter_search=1)\n",
    "            apr, roc = estimate(pos_test_, neg_test_, local_estimator, Vectorizer(4))\n",
    "            predictive_performances.append(roc)\n",
    "            print 'elapsed: %.1f sec'%(time()-start)\n",
    "    return predictive_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(pos_fname, neg_fname, size=None, percentages=None, n_repetitions=None, train_test_split=None):\n",
    "    # initializing \n",
    "    graphs_pos = get_graphs(pos_fname, size=size)\n",
    "    graphs_neg = get_graphs(neg_fname, size=size)\n",
    "\n",
    "    # train/test split\n",
    "    from eden.util import random_bipartition_iter\n",
    "    pos_train_global,pos_test_global = random_bipartition_iter(graphs_pos,train_test_split)\n",
    "    neg_train_global,neg_test_global = random_bipartition_iter(graphs_neg,train_test_split)\n",
    "\n",
    "\n",
    "    original_repetitions = []\n",
    "    original_sample_repetitions = []\n",
    "    sample_repetitions = []\n",
    "\n",
    "    for percentage in percentages:\n",
    "        originals = []\n",
    "        originals_samples = []\n",
    "        samples = []\n",
    "        for repetition in range(n_repetitions):\n",
    "            pos_train_global,pos_train_global_ = tee(pos_train_global)\n",
    "            neg_train_global,neg_train_global_ = tee(neg_train_global)\n",
    "            pos_test_global,pos_test_global_ = tee(pos_test_global)\n",
    "            neg_test_global,neg_test_global_ = tee(neg_test_global)\n",
    "\n",
    "            # use shuffled list to create test and sample set\n",
    "            pos,pos_reminder = random_bipartition_iter(pos_train_global_,percentage)\n",
    "            pos,pos_ = tee(pos)\n",
    "            neg,neg_reminder = random_bipartition_iter(neg_train_global_,percentage)\n",
    "            neg,neg_ = tee(neg)\n",
    "\n",
    "            #sample independently from the 2 classes\n",
    "            print('Positive')\n",
    "            sampled_pos = fit_sample(pos_)\n",
    "            print('Negative')\n",
    "            sampled_neg = fit_sample(neg_)\n",
    "\n",
    "            #evaluate the predictive performance on held out test set\n",
    "            start=time()\n",
    "            print \"=\"*80\n",
    "            print 'repetition: %d/%d'%(repetition+1, n_repetitions)\n",
    "            print \"training percentage:\"+str(percentage)\n",
    "            perf_orig,\\\n",
    "            perf_samp,\\\n",
    "            perf_orig_samp = fit_and_evaluate(pos,neg,\n",
    "                                              sampled_pos,sampled_neg,\n",
    "                                              pos_test_global_,neg_test_global_)\n",
    "            print 'Time elapsed: %.1f sec'%((time()-start))\n",
    "            originals.append(perf_orig)\n",
    "            originals_samples.append(perf_orig_samp)\n",
    "            samples.append(perf_samp)\n",
    "\n",
    "        original_repetitions.append(originals)\n",
    "        original_sample_repetitions.append(originals_samples)\n",
    "        sample_repetitions.append(samples)\n",
    "    \n",
    "    return original_repetitions, original_sample_repetitions, sample_repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with dataset: IGROV1_t\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#interfaces: 39   #cores: 40   #core-interface-pairs: 134\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#interfaces: 26   #cores: 37   #core-interface-pairs: 99\n",
      "================================================================================\n",
      "repetition: 1/5\n",
      "training percentage:0.05\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 28 #neg: 28\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.54      0.48      0.51       240\n",
      "          1       0.53      0.60      0.56       240\n",
      "\n",
      "avg / total       0.54      0.54      0.54       480\n",
      "\n",
      "APR: 0.578\n",
      "ROC: 0.539\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.658 +- 0.033\n",
      "           precision: 0.664 +- 0.045\n",
      "              recall: 0.650 +- 0.031\n",
      "                  f1: 0.656 +- 0.026\n",
      "   average_precision: 0.691 +- 0.022\n",
      "             roc_auc: 0.697 +- 0.012\n",
      "elapsed: 13.7 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 84 #neg: 84\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.51      0.68      0.58       240\n",
      "          1       0.51      0.33      0.40       240\n",
      "\n",
      "avg / total       0.51      0.51      0.49       480\n",
      "\n",
      "APR: 0.492\n",
      "ROC: 0.504\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.669 +- 0.015\n",
      "           precision: 0.671 +- 0.024\n",
      "              recall: 0.667 +- 0.026\n",
      "                  f1: 0.668 +- 0.012\n",
      "   average_precision: 0.684 +- 0.020\n",
      "             roc_auc: 0.699 +- 0.015\n",
      "elapsed: 11.0 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 112 #neg: 28\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.52      0.74      0.61       240\n",
      "          1       0.55      0.32      0.40       240\n",
      "\n",
      "avg / total       0.54      0.53      0.51       480\n",
      "\n",
      "APR: 0.581\n",
      "ROC: 0.560\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.650 +- 0.036\n",
      "           precision: 0.652 +- 0.046\n",
      "              recall: 0.654 +- 0.021\n",
      "                  f1: 0.652 +- 0.027\n",
      "   average_precision: 0.684 +- 0.033\n",
      "             roc_auc: 0.690 +- 0.030\n",
      "elapsed: 11.1 sec\n",
      "Time elapsed: 55.1 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#interfaces: 39   #cores: 40   #core-interface-pairs: 134\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#interfaces: 26   #cores: 37   #core-interface-pairs: 99\n",
      "================================================================================\n",
      "repetition: 2/5\n",
      "training percentage:0.05\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 28 #neg: 28\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.53      0.73      0.62       240\n",
      "          1       0.57      0.36      0.44       240\n",
      "\n",
      "avg / total       0.55      0.55      0.53       480\n",
      "\n",
      "APR: 0.611\n",
      "ROC: 0.573\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.654 +- 0.024\n",
      "           precision: 0.658 +- 0.034\n",
      "              recall: 0.650 +- 0.038\n",
      "                  f1: 0.653 +- 0.020\n",
      "   average_precision: 0.683 +- 0.037\n",
      "             roc_auc: 0.699 +- 0.030\n",
      "elapsed: 13.8 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 84 #neg: 84\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.55      0.81      0.65       240\n",
      "          1       0.64      0.33      0.43       240\n",
      "\n",
      "avg / total       0.59      0.57      0.54       480\n",
      "\n",
      "APR: 0.614\n",
      "ROC: 0.604\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.656 +- 0.029\n",
      "           precision: 0.663 +- 0.045\n",
      "              recall: 0.646 +- 0.026\n",
      "                  f1: 0.653 +- 0.020\n",
      "   average_precision: 0.690 +- 0.040\n",
      "             roc_auc: 0.693 +- 0.028\n",
      "elapsed: 11.0 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 112 #neg: 28\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.52      0.75      0.62       240\n",
      "          1       0.56      0.31      0.40       240\n",
      "\n",
      "avg / total       0.54      0.53      0.51       480\n",
      "\n",
      "APR: 0.583\n",
      "ROC: 0.561\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.635 +- 0.042\n",
      "           precision: 0.645 +- 0.053\n",
      "              recall: 0.613 +- 0.047\n",
      "                  f1: 0.627 +- 0.040\n",
      "   average_precision: 0.689 +- 0.039\n",
      "             roc_auc: 0.686 +- 0.030\n",
      "elapsed: 10.2 sec\n",
      "Time elapsed: 53.2 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#interfaces: 39   #cores: 40   #core-interface-pairs: 134\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#interfaces: 26   #cores: 37   #core-interface-pairs: 99\n",
      "================================================================================\n",
      "repetition: 3/5\n",
      "training percentage:0.05\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 28 #neg: 28\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.55      0.70      0.61       240\n",
      "          1       0.59      0.43      0.50       240\n",
      "\n",
      "avg / total       0.57      0.56      0.55       480\n",
      "\n",
      "APR: 0.598\n",
      "ROC: 0.580\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.640 +- 0.044\n",
      "           precision: 0.654 +- 0.053\n",
      "              recall: 0.600 +- 0.044\n",
      "                  f1: 0.625 +- 0.043\n",
      "   average_precision: 0.701 +- 0.026\n",
      "             roc_auc: 0.701 +- 0.033\n",
      "elapsed: 12.7 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 84 #neg: 84\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.57      0.80      0.66       240\n",
      "          1       0.65      0.39      0.49       240\n",
      "\n",
      "avg / total       0.61      0.59      0.57       480\n",
      "\n",
      "APR: 0.647\n",
      "ROC: 0.647\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.654 +- 0.040\n",
      "           precision: 0.664 +- 0.059\n",
      "              recall: 0.642 +- 0.028\n",
      "                  f1: 0.651 +- 0.026\n",
      "   average_precision: 0.684 +- 0.030\n",
      "             roc_auc: 0.692 +- 0.026\n",
      "elapsed: 12.5 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 112 #neg: 28\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.55      0.85      0.67       240\n",
      "          1       0.66      0.29      0.40       240\n",
      "\n",
      "avg / total       0.60      0.57      0.53       480\n",
      "\n",
      "APR: 0.636\n",
      "ROC: 0.618\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.650 +- 0.035\n",
      "           precision: 0.661 +- 0.053\n",
      "              recall: 0.629 +- 0.040\n",
      "                  f1: 0.643 +- 0.028\n",
      "   average_precision: 0.691 +- 0.025\n",
      "             roc_auc: 0.702 +- 0.025\n",
      "elapsed: 14.6 sec\n",
      "Time elapsed: 62.0 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#interfaces: 39   #cores: 40   #core-interface-pairs: 134\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#interfaces: 26   #cores: 37   #core-interface-pairs: 99\n",
      "================================================================================\n",
      "repetition: 4/5\n",
      "training percentage:0.05\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 28 #neg: 28\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.54      0.60      0.57       240\n",
      "          1       0.55      0.48      0.51       240\n",
      "\n",
      "avg / total       0.54      0.54      0.54       480\n",
      "\n",
      "APR: 0.613\n",
      "ROC: 0.589\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.652 +- 0.039\n",
      "           precision: 0.655 +- 0.048\n",
      "              recall: 0.650 +- 0.024\n",
      "                  f1: 0.652 +- 0.031\n",
      "   average_precision: 0.681 +- 0.033\n",
      "             roc_auc: 0.691 +- 0.026\n",
      "elapsed: 8.4 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 84 #neg: 84\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.53      0.54      0.54       240\n",
      "          1       0.53      0.53      0.53       240\n",
      "\n",
      "avg / total       0.53      0.53      0.53       480\n",
      "\n",
      "APR: 0.553\n",
      "ROC: 0.561\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.658 +- 0.025\n",
      "           precision: 0.665 +- 0.041\n",
      "              recall: 0.650 +- 0.036\n",
      "                  f1: 0.656 +- 0.016\n",
      "   average_precision: 0.697 +- 0.033\n",
      "             roc_auc: 0.702 +- 0.017\n",
      "elapsed: 13.4 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 112 #neg: 28\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.54      0.82      0.65       240\n",
      "          1       0.62      0.30      0.40       240\n",
      "\n",
      "avg / total       0.58      0.56      0.53       480\n",
      "\n",
      "APR: 0.604\n",
      "ROC: 0.552\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.631 +- 0.025\n",
      "           precision: 0.635 +- 0.034\n",
      "              recall: 0.629 +- 0.038\n",
      "                  f1: 0.630 +- 0.018\n",
      "   average_precision: 0.667 +- 0.026\n",
      "             roc_auc: 0.683 +- 0.020\n",
      "elapsed: 16.5 sec\n",
      "Time elapsed: 62.4 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#interfaces: 39   #cores: 40   #core-interface-pairs: 134\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#interfaces: 26   #cores: 37   #core-interface-pairs: 99\n",
      "================================================================================\n",
      "repetition: 5/5\n",
      "training percentage:0.05\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 28 #neg: 28\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.55      0.57      0.56       240\n",
      "          1       0.55      0.53      0.54       240\n",
      "\n",
      "avg / total       0.55      0.55      0.55       480\n",
      "\n",
      "APR: 0.623\n",
      "ROC: 0.596\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.652 +- 0.036\n",
      "           precision: 0.662 +- 0.050\n",
      "              recall: 0.633 +- 0.025\n",
      "                  f1: 0.646 +- 0.025\n",
      "   average_precision: 0.694 +- 0.037\n",
      "             roc_auc: 0.701 +- 0.020\n",
      "elapsed: 9.5 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 84 #neg: 84\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.54      0.59      0.57       240\n",
      "          1       0.55      0.50      0.53       240\n",
      "\n",
      "avg / total       0.55      0.55      0.55       480\n",
      "\n",
      "APR: 0.601\n",
      "ROC: 0.576\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.648 +- 0.021\n",
      "           precision: 0.652 +- 0.031\n",
      "              recall: 0.642 +- 0.033\n",
      "                  f1: 0.646 +- 0.017\n",
      "   average_precision: 0.686 +- 0.027\n",
      "             roc_auc: 0.697 +- 0.028\n",
      "elapsed: 18.0 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 112 #neg: 28\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.53      0.71      0.61       240\n",
      "          1       0.57      0.38      0.46       240\n",
      "\n",
      "avg / total       0.55      0.55      0.53       480\n",
      "\n",
      "APR: 0.596\n",
      "ROC: 0.577\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.660 +- 0.032\n",
      "           precision: 0.666 +- 0.047\n",
      "              recall: 0.654 +- 0.010\n",
      "                  f1: 0.659 +- 0.019\n",
      "   average_precision: 0.693 +- 0.033\n",
      "             roc_auc: 0.699 +- 0.027\n",
      "elapsed: 16.2 sec\n",
      "Time elapsed: 65.3 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#interfaces: 80   #cores: 75   #core-interface-pairs: 366\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#interfaces: 68   #cores: 78   #core-interface-pairs: 319\n",
      "================================================================================\n",
      "repetition: 1/5\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 112 #neg: 112\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.68      0.69      0.69       240\n",
      "          1       0.69      0.68      0.68       240\n",
      "\n",
      "avg / total       0.69      0.69      0.69       480\n",
      "\n",
      "APR: 0.682\n",
      "ROC: 0.732\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.646 +- 0.029\n",
      "           precision: 0.649 +- 0.040\n",
      "              recall: 0.646 +- 0.035\n",
      "                  f1: 0.646 +- 0.024\n",
      "   average_precision: 0.684 +- 0.027\n",
      "             roc_auc: 0.689 +- 0.029\n",
      "elapsed: 13.1 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 336 #neg: 336\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.63      0.75      0.68       240\n",
      "          1       0.69      0.55      0.61       240\n",
      "\n",
      "avg / total       0.66      0.65      0.65       480\n",
      "\n",
      "APR: 0.633\n",
      "ROC: 0.705\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.662 +- 0.025\n",
      "           precision: 0.671 +- 0.039\n",
      "              recall: 0.646 +- 0.023\n",
      "                  f1: 0.657 +- 0.015\n",
      "   average_precision: 0.687 +- 0.031\n",
      "             roc_auc: 0.696 +- 0.018\n",
      "elapsed: 20.1 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 448 #neg: 112\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.63      0.78      0.69       240\n",
      "          1       0.70      0.54      0.61       240\n",
      "\n",
      "avg / total       0.67      0.66      0.65       480\n",
      "\n",
      "APR: 0.658\n",
      "ROC: 0.708\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.640 +- 0.045\n",
      "           precision: 0.649 +- 0.054\n",
      "              recall: 0.617 +- 0.041\n",
      "                  f1: 0.631 +- 0.042\n",
      "   average_precision: 0.683 +- 0.032\n",
      "             roc_auc: 0.699 +- 0.027\n",
      "elapsed: 18.3 sec\n",
      "Time elapsed: 114.1 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#interfaces: 80   #cores: 75   #core-interface-pairs: 366\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#interfaces: 68   #cores: 78   #core-interface-pairs: 319\n",
      "================================================================================\n",
      "repetition: 2/5\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 112 #neg: 112\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.65      0.67      0.66       240\n",
      "          1       0.66      0.65      0.65       240\n",
      "\n",
      "avg / total       0.66      0.66      0.66       480\n",
      "\n",
      "APR: 0.670\n",
      "ROC: 0.715\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.650 +- 0.032\n",
      "           precision: 0.661 +- 0.044\n",
      "              recall: 0.625 +- 0.042\n",
      "                  f1: 0.641 +- 0.030\n",
      "   average_precision: 0.692 +- 0.026\n",
      "             roc_auc: 0.696 +- 0.019\n",
      "elapsed: 14.1 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 336 #neg: 336\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.66      0.75      0.70       240\n",
      "          1       0.71      0.62      0.66       240\n",
      "\n",
      "avg / total       0.69      0.68      0.68       480\n",
      "\n",
      "APR: 0.668\n",
      "ROC: 0.723\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.660 +- 0.036\n",
      "           precision: 0.673 +- 0.053\n",
      "              recall: 0.637 +- 0.017\n",
      "                  f1: 0.653 +- 0.023\n",
      "   average_precision: 0.684 +- 0.028\n",
      "             roc_auc: 0.699 +- 0.013\n",
      "elapsed: 24.0 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 448 #neg: 112\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.63      0.74      0.68       240\n",
      "          1       0.68      0.57      0.62       240\n",
      "\n",
      "avg / total       0.66      0.65      0.65       480\n",
      "\n",
      "APR: 0.668\n",
      "ROC: 0.712\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.646 +- 0.036\n",
      "           precision: 0.652 +- 0.045\n",
      "              recall: 0.633 +- 0.031\n",
      "                  f1: 0.642 +- 0.029\n",
      "   average_precision: 0.690 +- 0.024\n",
      "             roc_auc: 0.694 +- 0.024\n",
      "elapsed: 25.8 sec\n",
      "Time elapsed: 112.3 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#interfaces: 80   #cores: 75   #core-interface-pairs: 366\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#interfaces: 68   #cores: 78   #core-interface-pairs: 319\n",
      "================================================================================\n",
      "repetition: 3/5\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 112 #neg: 112\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.65      0.71      0.68       240\n",
      "          1       0.68      0.62      0.65       240\n",
      "\n",
      "avg / total       0.67      0.66      0.66       480\n",
      "\n",
      "APR: 0.694\n",
      "ROC: 0.725\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.644 +- 0.045\n",
      "           precision: 0.653 +- 0.060\n",
      "              recall: 0.629 +- 0.036\n",
      "                  f1: 0.639 +- 0.037\n",
      "   average_precision: 0.691 +- 0.037\n",
      "             roc_auc: 0.701 +- 0.033\n",
      "elapsed: 10.0 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 336 #neg: 336\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.64      0.65      0.64       240\n",
      "          1       0.64      0.63      0.64       240\n",
      "\n",
      "avg / total       0.64      0.64      0.64       480\n",
      "\n",
      "APR: 0.643\n",
      "ROC: 0.692\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.665 +- 0.039\n",
      "           precision: 0.673 +- 0.054\n",
      "              recall: 0.654 +- 0.021\n",
      "                  f1: 0.662 +- 0.027\n",
      "   average_precision: 0.694 +- 0.027\n",
      "             roc_auc: 0.702 +- 0.019\n",
      "elapsed: 26.4 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 448 #neg: 112\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.63      0.74      0.68       240\n",
      "          1       0.69      0.57      0.62       240\n",
      "\n",
      "avg / total       0.66      0.65      0.65       480\n",
      "\n",
      "APR: 0.649\n",
      "ROC: 0.706\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.654 +- 0.032\n",
      "           precision: 0.660 +- 0.038\n",
      "              recall: 0.642 +- 0.033\n",
      "                  f1: 0.650 +- 0.030\n",
      "   average_precision: 0.686 +- 0.017\n",
      "             roc_auc: 0.697 +- 0.012\n",
      "elapsed: 15.5 sec\n",
      "Time elapsed: 115.7 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#interfaces: 80   #cores: 75   #core-interface-pairs: 366\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#interfaces: 68   #cores: 78   #core-interface-pairs: 319\n",
      "================================================================================\n",
      "repetition: 4/5\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 112 #neg: 112\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.66      0.69      0.67       240\n",
      "          1       0.67      0.65      0.66       240\n",
      "\n",
      "avg / total       0.67      0.67      0.67       480\n",
      "\n",
      "APR: 0.675\n",
      "ROC: 0.722\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.652 +- 0.034\n",
      "           precision: 0.661 +- 0.047\n",
      "              recall: 0.637 +- 0.049\n",
      "                  f1: 0.647 +- 0.029\n",
      "   average_precision: 0.689 +- 0.028\n",
      "             roc_auc: 0.696 +- 0.027\n",
      "elapsed: 11.2 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 336 #neg: 336\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.68      0.66      0.67       240\n",
      "          1       0.67      0.68      0.68       240\n",
      "\n",
      "avg / total       0.67      0.67      0.67       480\n",
      "\n",
      "APR: 0.668\n",
      "ROC: 0.706\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.662 +- 0.038\n",
      "           precision: 0.668 +- 0.052\n",
      "              recall: 0.658 +- 0.031\n",
      "                  f1: 0.662 +- 0.027\n",
      "   average_precision: 0.702 +- 0.039\n",
      "             roc_auc: 0.697 +- 0.023\n",
      "elapsed: 18.9 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 448 #neg: 112\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.64      0.77      0.70       240\n",
      "          1       0.72      0.57      0.64       240\n",
      "\n",
      "avg / total       0.68      0.67      0.67       480\n",
      "\n",
      "APR: 0.671\n",
      "ROC: 0.717\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.673 +- 0.045\n",
      "           precision: 0.682 +- 0.062\n",
      "              recall: 0.662 +- 0.036\n",
      "                  f1: 0.670 +- 0.037\n",
      "   average_precision: 0.698 +- 0.021\n",
      "             roc_auc: 0.710 +- 0.015\n",
      "elapsed: 19.0 sec\n",
      "Time elapsed: 121.0 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#interfaces: 80   #cores: 75   #core-interface-pairs: 366\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#interfaces: 68   #cores: 78   #core-interface-pairs: 319\n",
      "================================================================================\n",
      "repetition: 5/5\n",
      "training percentage:0.2\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 112 #neg: 112\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.66      0.66      0.66       240\n",
      "          1       0.66      0.66      0.66       240\n",
      "\n",
      "avg / total       0.66      0.66      0.66       480\n",
      "\n",
      "APR: 0.655\n",
      "ROC: 0.713\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.656 +- 0.033\n",
      "           precision: 0.662 +- 0.045\n",
      "              recall: 0.650 +- 0.028\n",
      "                  f1: 0.655 +- 0.023\n",
      "   average_precision: 0.689 +- 0.039\n",
      "             roc_auc: 0.701 +- 0.019\n",
      "elapsed: 16.8 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 336 #neg: 336\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.62      0.75      0.68       240\n",
      "          1       0.68      0.55      0.61       240\n",
      "\n",
      "avg / total       0.65      0.65      0.64       480\n",
      "\n",
      "APR: 0.632\n",
      "ROC: 0.688\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.658 +- 0.029\n",
      "           precision: 0.666 +- 0.043\n",
      "              recall: 0.646 +- 0.032\n",
      "                  f1: 0.654 +- 0.021\n",
      "   average_precision: 0.695 +- 0.028\n",
      "             roc_auc: 0.706 +- 0.019\n",
      "elapsed: 20.6 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 448 #neg: 112\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.65      0.75      0.69       240\n",
      "          1       0.70      0.60      0.64       240\n",
      "\n",
      "avg / total       0.67      0.67      0.67       480\n",
      "\n",
      "APR: 0.661\n",
      "ROC: 0.713\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.646 +- 0.035\n",
      "           precision: 0.657 +- 0.051\n",
      "              recall: 0.625 +- 0.035\n",
      "                  f1: 0.639 +- 0.026\n",
      "   average_precision: 0.664 +- 0.026\n",
      "             roc_auc: 0.681 +- 0.017\n",
      "elapsed: 26.4 sec\n",
      "Time elapsed: 115.5 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#interfaces: 104   #cores: 103   #core-interface-pairs: 543\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#interfaces: 96   #cores: 102   #core-interface-pairs: 481\n",
      "================================================================================\n",
      "repetition: 1/5\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 224 #neg: 224\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.68      0.70      0.69       240\n",
      "          1       0.69      0.68      0.68       240\n",
      "\n",
      "avg / total       0.69      0.69      0.69       480\n",
      "\n",
      "APR: 0.701\n",
      "ROC: 0.741\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.660 +- 0.047\n",
      "           precision: 0.668 +- 0.062\n",
      "              recall: 0.650 +- 0.033\n",
      "                  f1: 0.658 +- 0.039\n",
      "   average_precision: 0.690 +- 0.035\n",
      "             roc_auc: 0.706 +- 0.029\n",
      "elapsed: 11.7 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 672 #neg: 670\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.66      0.74      0.70       240\n",
      "          1       0.70      0.62      0.66       240\n",
      "\n",
      "avg / total       0.68      0.68      0.68       480\n",
      "\n",
      "APR: 0.685\n",
      "ROC: 0.737\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.652 +- 0.040\n",
      "           precision: 0.656 +- 0.047\n",
      "              recall: 0.646 +- 0.040\n",
      "                  f1: 0.650 +- 0.036\n",
      "   average_precision: 0.691 +- 0.039\n",
      "             roc_auc: 0.698 +- 0.028\n",
      "elapsed: 29.0 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 896 #neg: 224\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.67      0.77      0.71       240\n",
      "          1       0.73      0.61      0.67       240\n",
      "\n",
      "avg / total       0.70      0.69      0.69       480\n",
      "\n",
      "APR: 0.679\n",
      "ROC: 0.741\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.625 +- 0.034\n",
      "           precision: 0.625 +- 0.041\n",
      "              recall: 0.633 +- 0.031\n",
      "                  f1: 0.628 +- 0.028\n",
      "   average_precision: 0.683 +- 0.033\n",
      "             roc_auc: 0.694 +- 0.015\n",
      "elapsed: 25.9 sec\n",
      "Time elapsed: 182.2 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#interfaces: 104   #cores: 103   #core-interface-pairs: 543\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#interfaces: 96   #cores: 102   #core-interface-pairs: 481\n",
      "================================================================================\n",
      "repetition: 2/5\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 224 #neg: 224\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.69      0.72      0.70       240\n",
      "          1       0.71      0.68      0.69       240\n",
      "\n",
      "avg / total       0.70      0.70      0.70       480\n",
      "\n",
      "APR: 0.709\n",
      "ROC: 0.754\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.660 +- 0.043\n",
      "           precision: 0.669 +- 0.057\n",
      "              recall: 0.650 +- 0.069\n",
      "                  f1: 0.656 +- 0.043\n",
      "   average_precision: 0.676 +- 0.031\n",
      "             roc_auc: 0.691 +- 0.029\n",
      "elapsed: 22.5 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 672 #neg: 670\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.66      0.67      0.67       240\n",
      "          1       0.67      0.66      0.66       240\n",
      "\n",
      "avg / total       0.66      0.66      0.66       480\n",
      "\n",
      "APR: 0.724\n",
      "ROC: 0.732\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.660 +- 0.036\n",
      "           precision: 0.671 +- 0.052\n",
      "              recall: 0.642 +- 0.016\n",
      "                  f1: 0.655 +- 0.025\n",
      "   average_precision: 0.685 +- 0.017\n",
      "             roc_auc: 0.697 +- 0.014\n",
      "elapsed: 43.6 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 896 #neg: 224\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.67      0.75      0.71       240\n",
      "          1       0.72      0.64      0.68       240\n",
      "\n",
      "avg / total       0.70      0.69      0.69       480\n",
      "\n",
      "APR: 0.683\n",
      "ROC: 0.735\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.665 +- 0.029\n",
      "           precision: 0.669 +- 0.041\n",
      "              recall: 0.658 +- 0.010\n",
      "                  f1: 0.663 +- 0.021\n",
      "   average_precision: 0.687 +- 0.025\n",
      "             roc_auc: 0.710 +- 0.015\n",
      "elapsed: 44.8 sec\n",
      "Time elapsed: 215.6 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#interfaces: 104   #cores: 103   #core-interface-pairs: 543\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#interfaces: 96   #cores: 102   #core-interface-pairs: 481\n",
      "================================================================================\n",
      "repetition: 3/5\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 224 #neg: 224\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.69      0.71      0.70       240\n",
      "          1       0.70      0.69      0.69       240\n",
      "\n",
      "avg / total       0.70      0.70      0.70       480\n",
      "\n",
      "APR: 0.715\n",
      "ROC: 0.750\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.667 +- 0.031\n",
      "           precision: 0.673 +- 0.045\n",
      "              recall: 0.658 +- 0.034\n",
      "                  f1: 0.664 +- 0.024\n",
      "   average_precision: 0.683 +- 0.023\n",
      "             roc_auc: 0.707 +- 0.021\n",
      "elapsed: 15.0 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 672 #neg: 670\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.65      0.71      0.68       240\n",
      "          1       0.68      0.62      0.65       240\n",
      "\n",
      "avg / total       0.66      0.66      0.66       480\n",
      "\n",
      "APR: 0.678\n",
      "ROC: 0.716\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.654 +- 0.041\n",
      "           precision: 0.661 +- 0.056\n",
      "              recall: 0.646 +- 0.046\n",
      "                  f1: 0.652 +- 0.036\n",
      "   average_precision: 0.684 +- 0.035\n",
      "             roc_auc: 0.695 +- 0.023\n",
      "elapsed: 27.3 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 896 #neg: 224\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.66      0.77      0.71       240\n",
      "          1       0.72      0.61      0.66       240\n",
      "\n",
      "avg / total       0.69      0.69      0.69       480\n",
      "\n",
      "APR: 0.681\n",
      "ROC: 0.728\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.662 +- 0.027\n",
      "           precision: 0.672 +- 0.036\n",
      "              recall: 0.642 +- 0.040\n",
      "                  f1: 0.655 +- 0.026\n",
      "   average_precision: 0.707 +- 0.020\n",
      "             roc_auc: 0.705 +- 0.017\n",
      "elapsed: 24.5 sec\n",
      "Time elapsed: 179.5 sec\n",
      "Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/costa/anaconda/lib/python2.7/site-packages/sklearn/calibration.py:398: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "/Users/costa/anaconda/lib/python2.7/site-packages/sklearn/calibration.py:408: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "/Users/costa/anaconda/lib/python2.7/site-packages/sklearn/calibration.py:410: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph grammar stats:\n",
      "#interfaces: 104   #cores: 103   #core-interface-pairs: 543\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#interfaces: 96   #cores: 102   #core-interface-pairs: 481\n",
      "================================================================================\n",
      "repetition: 4/5\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 224 #neg: 224\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.68      0.74      0.71       240\n",
      "          1       0.71      0.66      0.69       240\n",
      "\n",
      "avg / total       0.70      0.70      0.70       480\n",
      "\n",
      "APR: 0.715\n",
      "ROC: 0.757\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.675 +- 0.040\n",
      "           precision: 0.686 +- 0.060\n",
      "              recall: 0.662 +- 0.028\n",
      "                  f1: 0.672 +- 0.024\n",
      "   average_precision: 0.693 +- 0.038\n",
      "             roc_auc: 0.705 +- 0.024\n",
      "elapsed: 21.5 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 672 #neg: 670\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.66      0.77      0.71       240\n",
      "          1       0.72      0.60      0.65       240\n",
      "\n",
      "avg / total       0.69      0.68      0.68       480\n",
      "\n",
      "APR: 0.703\n",
      "ROC: 0.741\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.652 +- 0.039\n",
      "           precision: 0.660 +- 0.054\n",
      "              recall: 0.642 +- 0.024\n",
      "                  f1: 0.649 +- 0.029\n",
      "   average_precision: 0.700 +- 0.032\n",
      "             roc_auc: 0.703 +- 0.025\n",
      "elapsed: 35.7 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 896 #neg: 224\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.66      0.76      0.71       240\n",
      "          1       0.72      0.60      0.66       240\n",
      "\n",
      "avg / total       0.69      0.68      0.68       480\n",
      "\n",
      "APR: 0.683\n",
      "ROC: 0.732\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.644 +- 0.047\n",
      "           precision: 0.653 +- 0.058\n",
      "              recall: 0.625 +- 0.044\n",
      "                  f1: 0.637 +- 0.041\n",
      "   average_precision: 0.692 +- 0.025\n",
      "             roc_auc: 0.694 +- 0.029\n",
      "elapsed: 38.7 sec\n",
      "Time elapsed: 181.1 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#interfaces: 104   #cores: 103   #core-interface-pairs: 543\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#interfaces: 96   #cores: 102   #core-interface-pairs: 481\n",
      "================================================================================\n",
      "repetition: 5/5\n",
      "training percentage:0.4\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 224 #neg: 224\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.69      0.70      0.69       240\n",
      "          1       0.69      0.69      0.69       240\n",
      "\n",
      "avg / total       0.69      0.69      0.69       480\n",
      "\n",
      "APR: 0.718\n",
      "ROC: 0.744\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.660 +- 0.040\n",
      "           precision: 0.672 +- 0.062\n",
      "              recall: 0.646 +- 0.042\n",
      "                  f1: 0.656 +- 0.029\n",
      "   average_precision: 0.682 +- 0.022\n",
      "             roc_auc: 0.702 +- 0.022\n",
      "elapsed: 12.8 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 672 #neg: 670\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.64      0.75      0.69       240\n",
      "          1       0.70      0.59      0.64       240\n",
      "\n",
      "avg / total       0.67      0.67      0.66       480\n",
      "\n",
      "APR: 0.695\n",
      "ROC: 0.733\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.650 +- 0.036\n",
      "           precision: 0.657 +- 0.047\n",
      "              recall: 0.633 +- 0.047\n",
      "                  f1: 0.644 +- 0.036\n",
      "   average_precision: 0.681 +- 0.019\n",
      "             roc_auc: 0.697 +- 0.022\n",
      "elapsed: 26.2 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 896 #neg: 224\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.66      0.76      0.71       240\n",
      "          1       0.72      0.60      0.66       240\n",
      "\n",
      "avg / total       0.69      0.68      0.68       480\n",
      "\n",
      "APR: 0.683\n",
      "ROC: 0.731\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.671 +- 0.040\n",
      "           precision: 0.680 +- 0.049\n",
      "              recall: 0.650 +- 0.044\n",
      "                  f1: 0.664 +- 0.040\n",
      "   average_precision: 0.678 +- 0.025\n",
      "             roc_auc: 0.698 +- 0.016\n",
      "elapsed: 27.8 sec\n",
      "Time elapsed: 182.0 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#interfaces: 132   #cores: 126   #core-interface-pairs: 705\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#interfaces: 120   #cores: 123   #core-interface-pairs: 630\n",
      "================================================================================\n",
      "repetition: 1/5\n",
      "training percentage:0.6\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 336 #neg: 336\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.69      0.73      0.71       240\n",
      "          1       0.71      0.68      0.69       240\n",
      "\n",
      "avg / total       0.70      0.70      0.70       480\n",
      "\n",
      "APR: 0.749\n",
      "ROC: 0.771\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.656 +- 0.039\n",
      "           precision: 0.658 +- 0.046\n",
      "              recall: 0.658 +- 0.031\n",
      "                  f1: 0.657 +- 0.034\n",
      "   average_precision: 0.683 +- 0.054\n",
      "             roc_auc: 0.700 +- 0.027\n",
      "elapsed: 14.6 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on sample\n",
      "training set sizes: #pos: 1008 #neg: 1006\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.67      0.71      0.69       240\n",
      "          1       0.69      0.65      0.67       240\n",
      "\n",
      "avg / total       0.68      0.68      0.68       480\n",
      "\n",
      "APR: 0.720\n",
      "ROC: 0.744\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.658 +- 0.032\n",
      "           precision: 0.667 +- 0.045\n",
      "              recall: 0.642 +- 0.031\n",
      "                  f1: 0.653 +- 0.023\n",
      "   average_precision: 0.686 +- 0.030\n",
      "             roc_auc: 0.699 +- 0.028\n",
      "elapsed: 35.5 sec\n",
      "--------------------------------------------------------------------------------\n",
      "working on original+sample\n",
      "training set sizes: #pos: 1344 #neg: 336\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.66      0.75      0.70       240\n",
      "          1       0.71      0.61      0.66       240\n",
      "\n",
      "avg / total       0.69      0.68      0.68       480\n",
      "\n",
      "APR: 0.693\n",
      "ROC: 0.739\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.671 +- 0.033\n",
      "           precision: 0.675 +- 0.049\n",
      "              recall: 0.675 +- 0.045\n",
      "                  f1: 0.672 +- 0.024\n",
      "   average_precision: 0.681 +- 0.022\n",
      "             roc_auc: 0.705 +- 0.016\n",
      "elapsed: 34.4 sec\n",
      "Time elapsed: 245.2 sec\n",
      "Positive\n",
      "graph grammar stats:\n",
      "#interfaces: 132   #cores: 126   #core-interface-pairs: 705\n",
      "Negative\n",
      "graph grammar stats:\n",
      "#interfaces: 120   #cores: 123   #core-interface-pairs: 630\n",
      "================================================================================\n",
      "repetition: 2/5\n",
      "training percentage:0.6\n",
      "--------------------------------------------------------------------------------\n",
      "working on original\n",
      "training set sizes: #pos: 336 #neg: 336\n",
      "Test set\n",
      "Instances: 480 ; Features: 1048577 with an avg of 437 features per instance\n",
      "--------------------------------------------------------------------------------\n",
      "Test Estimate\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.68      0.71      0.69       240\n",
      "          1       0.70      0.67      0.68       240\n",
      "\n",
      "avg / total       0.69      0.69      0.69       480\n",
      "\n",
      "APR: 0.743\n",
      "ROC: 0.761\n",
      "Cross-validated estimate\n",
      "            accuracy: 0.667 +- 0.046\n",
      "           precision: 0.684 +- 0.060\n",
      "              recall: 0.629 +- 0.031\n",
      "                  f1: 0.655 +- 0.039\n",
      "   average_precision: 0.691 +- 0.042\n",
      "             roc_auc: 0.709 +- 0.030\n",
      "elapsed: 24.6 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9f1e9180cf12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"#experiment\\n\\ndataset_names = !cat NCI60/names\\ndataset = dataset_names[6]\\nprint 'Working with dataset: %s' % dataset \\npos_dataset_fname = 'NCI60/' + dataset + '_orig_pos.gspan'\\nneg_dataset_fname = 'NCI60/' + dataset + '_orig_neg.gspan'\\n\\n#pos_dataset_fname = 'bursi.pos.gspan'\\n#neg_dataset_fname = 'bursi.neg.gspan'\\n\\n\\npercentages=[.05,.2,.4,.6,.8,.95]\\n\\noriginal_repetitions,\\\\\\noriginal_sample_repetitions,\\\\\\nsample_repetitions = evaluate(pos_dataset_fname,neg_dataset_fname,\\n                              size=800,\\n                              percentages=percentages,\\n                              n_repetitions=5,\\n                              train_test_split=0.7)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/costa/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2262\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2263\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2264\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2265\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/costa/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/costa/anaconda/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/costa/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-8e72f52c2542>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(pos_fname, neg_fname, size, percentages, n_repetitions, train_test_split)\u001b[0m\n\u001b[1;32m     43\u001b[0m             perf_orig,            perf_samp,            perf_orig_samp = fit_and_evaluate(pos,neg,\n\u001b[1;32m     44\u001b[0m                                               \u001b[0msampled_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msampled_neg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                                               pos_test_global_,neg_test_global_)\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m'Time elapsed: %.1f sec'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0moriginals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-75d563103f9f>\u001b[0m in \u001b[0;36mfit_and_evaluate\u001b[0;34m(pos_original, neg_original, pos_sampled, neg_sampled, pos_test, neg_test)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mneg_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneg_train_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mpos_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mneg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneg_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mneg_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-75d563103f9f>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((x,))\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mneg_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneg_train_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mpos_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mneg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneg_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mneg_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/costa/Desktop/BTSync/Projects/graphlearn/example/graphlearn/graphlearn.pyc\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, graph_iter, probabilistic_core_choice, score_core_choice, max_core_size_diff, similarity, n_samples, batch_size, n_jobs, target_orig_cip, n_steps, improving_threshold, accept_static_penalty, select_cip_max_tries, burnin, generator_mode, keep_duplicates)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0msampled_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sample_multi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_argbuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampled_graphs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msampled_graph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mnew_graph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/costa/anaconda/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/costa/anaconda/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#experiment\n",
    "\n",
    "dataset_names = !cat NCI60/names\n",
    "dataset = dataset_names[6]\n",
    "print 'Working with dataset: %s' % dataset \n",
    "pos_dataset_fname = 'NCI60/' + dataset + '_orig_pos.gspan'\n",
    "neg_dataset_fname = 'NCI60/' + dataset + '_orig_neg.gspan'\n",
    "\n",
    "#pos_dataset_fname = 'bursi.pos.gspan'\n",
    "#neg_dataset_fname = 'bursi.neg.gspan'\n",
    "configure_logging(logging.getLogger(),verbosity=1, filename='%_predictive_performance_of_samples.log'%dataset)\n",
    "\n",
    "\n",
    "percentages=[.05,.2,.4,.6,.8,.95]\n",
    "\n",
    "original_repetitions,\\\n",
    "original_sample_repetitions,\\\n",
    "sample_repetitions = evaluate(pos_dataset_fname,neg_dataset_fname,\n",
    "                              size=600,\n",
    "                              percentages=percentages,\n",
    "                              n_repetitions=3,\n",
    "                              train_test_split=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "gc={'color':'g'}\n",
    "rc={'color':'r'}\n",
    "bc={'color':'b'}\n",
    "ws = 0.02\n",
    "os = np.mean(original_sample_repetitions, axis=1)\n",
    "o = np.mean(original_repetitions, axis=1)\n",
    "s = np.mean(sample_repetitions, axis=1)\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.grid()\n",
    "plt.boxplot(original_sample_repetitions, positions=percentages, widths=ws, capprops=gc, medianprops=gc, boxprops=gc, whiskerprops=gc, flierprops=gc)\n",
    "plt.plot(percentages,os, color='g', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='g', markerfacecolor='w', label='original+sample')\n",
    "\n",
    "plt.boxplot(original_repetitions, positions=percentages, widths=ws, capprops=rc, medianprops=rc, boxprops=rc, whiskerprops=rc, flierprops=rc)\n",
    "plt.plot(percentages,o, color='r', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='r', markerfacecolor='w', label='original')\n",
    "\n",
    "plt.boxplot(sample_repetitions, positions=percentages, widths=ws, capprops=bc, medianprops=bc, boxprops=bc, whiskerprops=bc, flierprops=bc)\n",
    "plt.plot(percentages,s, color='b', marker='o', markeredgewidth=1, markersize=7, markeredgecolor='b', markerfacecolor='w', label='sample')\n",
    "\n",
    "plt.xlim(percentages[0]-.1,percentages[-1]+.1)\n",
    "plt.ylabel('ROC AUC',fontsize=16)\n",
    "plt.xlabel('Dataset size (fraction)',fontsize=16)\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('%s_plot_predictive_performance_of_samples.pdf' % dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
